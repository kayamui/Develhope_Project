{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmtfkpSu3tjHZBWcrWBdgr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kayamui/Develhope_Project/blob/main/hourlyCaseCounts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fU3eECF2hkKC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime # Import the datetime module\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path= 'C:/Users/mkaya/OneDrive/Masaüstü/istanbul112_hidden/data/case_reports/europe/'"
      ],
      "metadata": {
        "id": "05E6IWSgx2nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asia_path= 'C:/Users/mkaya/OneDrive/Masaüstü/istanbul112_hidden/data/case_reports/asia/'"
      ],
      "metadata": {
        "id": "lQtd74mJfZ-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unfinished_works_path= 'C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/unfinished_works/'"
      ],
      "metadata": {
        "id": "oPsi3u44X8AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WO2WneCKFTes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "excel_jan= pd.ExcelFile(path+'2024/monthly/'+'1-OCAK 2024 AVR ASOS TANIDÖNÜŞTÜRÜLMÜŞ DEFTER.xlsx')\n",
        "excel_feb= pd.ExcelFile(path+'2024/monthly/'+'2-ŞUBAT 2024 AVR ASOS TANIDÖNÜŞTÜRÜLMÜŞ DEFTER.xlsx')\n",
        "excel_mar= pd.ExcelFile(path+'2024/monthly/'+'3-MART 2024 AVR ASOS TANIDÖNÜŞTÜRÜLMÜŞ DEFTER.xlsx')\n",
        "excel_apr= pd.ExcelFile(path+'2024/monthly/'+'4-NİSAN 2024 AVR ASOS TANIDÖNÜŞTÜRÜLMÜŞ DEFTER.xlsx')\n",
        "excel_may= pd.ExcelFile(path+'2024/monthly/'+'5-MAYIS 2024 AVR ASOS TANIDÖNÜŞTÜRÜLMÜŞ DEFTER.xlsx')\n",
        "excel_jun= pd.ExcelFile(path+'2024/monthly/'+'6-HAZİRAN 2024 AVR ASOS TANIDÖNÜŞTÜRÜLMÜŞ DEFTER.xlsx')\n",
        "excel_jul= pd.ExcelFile(path+'2024/monthly/'+'7-TEMMUZ 2024 AVR ASOS TANIDÖNÜŞTÜRÜLMÜŞ DEFTER.xlsx')\n",
        "excel_aug= pd.ExcelFile(path+'2024/monthly/'+'8-AĞUSTOS 2024 AVR ASOS TANIDÖNÜŞTÜRÜLMÜŞ DEFTER.xlsx')"
      ],
      "metadata": {
        "id": "Jdl-mAGPSsbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "otoxsW4wewx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "excel_asia_janjul= pd.ExcelFile(asia_path+'2024/total/'+'janjul.xlsx')"
      ],
      "metadata": {
        "id": "1Sq8mH0Se_GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "excel_asia_2023_jandec= pd.ExcelFile(asia_path+'2023/total/'+'jandec.xlsx')"
      ],
      "metadata": {
        "id": "9lqP---VRwRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "excel_eu_2023_janjun= pd.ExcelFile(path+'2023/total/'+'janjun.xlsx')\n",
        "excel_eu_2023_juldec= pd.ExcelFile(path+'2023/total/'+'juldec.xlsx')"
      ],
      "metadata": {
        "id": "NntmR0appi73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZIabsUiVtmol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2023_janjun= {sheet_name: excel_eu_2023_janjun.parse(sheet_name) for sheet_name in excel_eu_2023_janjun.sheet_names}\n",
        "df_2023_juldec= {sheet_name: excel_eu_2023_juldec.parse(sheet_name) for sheet_name in excel_eu_2023_juldec.sheet_names}"
      ],
      "metadata": {
        "id": "eUhkYIKmp8fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia_2023_jandec= {sheet_name: excel_asia_2023_jandec.parse(sheet_name) for sheet_name in excel_asia_2023_jandec.sheet_names}\n",
        "print(df_asia_2023_jandec.keys())"
      ],
      "metadata": {
        "id": "NfQ-quYXR8dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_2023_janjun.keys())\n",
        "print(df_2023_juldec.keys())"
      ],
      "metadata": {
        "id": "p9rb4f3WIvDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2023_janjun_eu= df_2023_janjun['Sheet1']\n",
        "df_2023_juldec_eu= df_2023_juldec['Sheet1']\n",
        "df_2023_eu= pd.concat([df_2023_janjun_eu, df_2023_juldec_eu])"
      ],
      "metadata": {
        "id": "SgVeK91-s5br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2023_jandec_as= df_asia_2023_jandec['BİRLEŞTİRİLMİŞ']"
      ],
      "metadata": {
        "id": "s5KpjYe8TNXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = {sheet_name: excel_jan.parse(sheet_name) for sheet_name in excel_jan.sheet_names}\n",
        "df4 = {sheet_name: excel_feb.parse(sheet_name) for sheet_name in excel_feb.sheet_names}\n",
        "df5 = {sheet_name: excel_mar.parse(sheet_name) for sheet_name in excel_mar.sheet_names}\n",
        "df6 = {sheet_name: excel_apr.parse(sheet_name) for sheet_name in excel_apr.sheet_names}\n",
        "df7 = {sheet_name: excel_may.parse(sheet_name) for sheet_name in excel_may.sheet_names}\n",
        "df8 = {sheet_name: excel_jun.parse(sheet_name) for sheet_name in excel_jun.sheet_names}\n",
        "df9 = {sheet_name: excel_jul.parse(sheet_name) for sheet_name in excel_jul.sheet_names}\n",
        "df10= {sheet_name: excel_aug.parse(sheet_name) for sheet_name in excel_aug.sheet_names}"
      ],
      "metadata": {
        "id": "BnCfDnk2TFQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wLMbL6cLejvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df10.keys()"
      ],
      "metadata": {
        "id": "QeWo63J4fwC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_aug= df10['Sheet1']"
      ],
      "metadata": {
        "id": "E_D3ID25gb1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1= {sheet_name: excel_asia_janjul.parse(sheet_name) for sheet_name in excel_asia_janjul.sheet_names}"
      ],
      "metadata": {
        "id": "OVY6tGm0_zph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.keys()"
      ],
      "metadata": {
        "id": "cq9QJlvN_oL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia= df_1['BİRLEŞMİŞ DEFTER'].copy()"
      ],
      "metadata": {
        "id": "RQnzflA3hCqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[col for col in df_asia.columns]"
      ],
      "metadata": {
        "id": "_pImqsDHl2tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa= pd.concat([df3['54230'],df4['48247'], df5['49926'],df6['NİSAN - 50.014'], df7['52340'], df8['52852-DEFTER'], df9['55923 defter avrupa']])"
      ],
      "metadata": {
        "id": "OONvL0swFp6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa"
      ],
      "metadata": {
        "id": "80Z3b-fhfv05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names= pd.read_excel('C:/Users/mkaya/Downloads/callList (2).xlsx')"
      ],
      "metadata": {
        "id": "DJiWTStYbtVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names['Ekipteki Kişiler']= df_names['Ekipteki Kişiler'].str.strip()"
      ],
      "metadata": {
        "id": "z3xZCuddbtXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names_list= df_names['Ekipteki Kişiler'].tolist()\n",
        "names_list= list(set(names_list))"
      ],
      "metadata": {
        "id": "BriU5TVCbtaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_frame= pd.DataFrame()\n",
        "for name in names_list:\n",
        "  name_frame= pd.concat([name_frame, df_aug[df_aug['EKIPTEKI KISILER'].astype(str).str.contains(name)]])"
      ],
      "metadata": {
        "id": "s6KNqqhFgt_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names_list"
      ],
      "metadata": {
        "id": "0z2JS88Ig5AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_frame= pd.DataFrame()\n",
        "for name in names_list:\n",
        "  name_frame= pd.concat([name_frame, df_avrupa[df_avrupa['Ekipteki Kişiler'].astype(str).str.contains(name)]])"
      ],
      "metadata": {
        "id": "1gxbqYHfcdlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[col for col in name_frame.columns]"
      ],
      "metadata": {
        "id": "XMRHGpxIdMx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_frame= name_frame[['KKM PROTOKOL', 'EKIP NO',\"ISTASYON ICIN VAKA KAPATMA SURESI  (VAKA VERILIS   ILK KKM'YE GONDERIM)\", 'EKIPTEKI KISILER']]\n",
        "#name_frame= name_frame[['KKM Protokol', 'Ekip No',\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\", 'Ekipteki Kişiler']]\n",
        "name_frame.columns= ['KKM Protokol', 'Ekip No',\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\", 'Ekipteki Kişiler']"
      ],
      "metadata": {
        "id": "PIvQY9hJhCWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleared_name_frame= name_frame[['KKM Protokol', 'Ekip No', \"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\", 'Ekipteki Kişiler']].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "GYPdFE49btcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleared_name_frame['Ekipteki Kişiler']= cleared_name_frame['Ekipteki Kişiler'].str.split(',')\n",
        "cleared_name_frame= cleared_name_frame.explode('Ekipteki Kişiler')"
      ],
      "metadata": {
        "id": "Xfoi109nbteg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleared_name_frame= cleared_name_frame[~(cleared_name_frame['Ekipteki Kişiler'].str.contains('Sürücü'))]"
      ],
      "metadata": {
        "id": "2XeaBVLJd7_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleared_name_frame['Ekipteki Kişiler']= cleared_name_frame['Ekipteki Kişiler'].str.replace(' - Yardımcı Sağlık Personeli', '').str.replace(' - Ekip Sorumlusu', '')\n",
        "cleared_name_frame['Ekipteki Kişiler']= cleared_name_frame['Ekipteki Kişiler'].str.strip()\n",
        "cleared_name_frame"
      ],
      "metadata": {
        "id": "VBa5wVIed8Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use regular expressions to extract day, hour and minute information\n",
        "cleared_name_frame['day'] = cleared_name_frame[\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"].str.extract('(\\d+) Gün').astype(int)\n",
        "cleared_name_frame['hour'] = cleared_name_frame[\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"].str.extract('(\\d+) Saat').astype(int)\n",
        "cleared_name_frame['minute'] = cleared_name_frame[\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"].str.extract('(\\d+) Dakika').astype(int)\n",
        "\n",
        "# Convert the extracted information into timedelta objects\n",
        "cleared_name_frame[\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"] = pd.to_timedelta(cleared_name_frame.day * 24 + cleared_name_frame.hour, unit='h') + pd.to_timedelta(cleared_name_frame.minute, unit='m')\n",
        "\n",
        "# Drop the temporary columns\n",
        "cleared_name_frame = cleared_name_frame.drop(['day', 'hour', 'minute'], axis=1)"
      ],
      "metadata": {
        "id": "tjpfLJigd8EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleared_name_frame[\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"]= cleared_name_frame[\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"].dt.total_seconds() / 3600"
      ],
      "metadata": {
        "id": "j60jT6h5d8Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleared_name_frame[\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"]= round(cleared_name_frame[\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"],2)\n",
        "cleared_name_frame['value']= 1\n",
        "cleared_name_frame"
      ],
      "metadata": {
        "id": "6FBFaDJgd8KX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_grouped= cleared_name_frame.groupby('Ekipteki Kişiler').agg({\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\":'mean', 'value':'sum'}).reset_index().sort_values(by= \"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\", ascending=False).reset_index(drop=True)\n",
        "name_grouped"
      ],
      "metadata": {
        "id": "c2gkoTJCd8Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_grouped_aug= cleared_name_frame.groupby('Ekipteki Kişiler').agg({\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\":'mean', 'value':'sum'}).reset_index().sort_values(by= \"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\", ascending=False).reset_index(drop=True)\n",
        "name_grouped_aug= name_grouped_aug[~name_grouped_aug['Ekipteki Kişiler'].str.contains('Refakatçi')]\n",
        "name_grouped_aug[\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"]= round(name_grouped_aug[\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"],2)\n",
        "name_grouped_aug"
      ],
      "metadata": {
        "id": "jwYIsFDgiMkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_grouped= name_grouped[~name_grouped['Ekipteki Kişiler'].str.contains('Refakatçi')]\n",
        "name_grouped[\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"]= round(name_grouped[\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"],2)\n",
        "name_grouped"
      ],
      "metadata": {
        "id": "QSgtkt6fd8Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_grouped.columns= ['İsim', 'Gönderim Saati (OCAK-TEMMUZ)', 'Sayı (OCAK-TEMMUZ)']"
      ],
      "metadata": {
        "id": "1lNivvwZfxOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_grouped_aug.columns= ['İsim', 'Gönderim Saati (AĞUSTOS)', 'Sayı (AĞUSTOS)']"
      ],
      "metadata": {
        "id": "Jq2caeh0inPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_grouped['İsim']= name_grouped['İsim'].str.strip()\n",
        "name_grouped_aug['İsim']= name_grouped_aug['İsim'].str.strip()"
      ],
      "metadata": {
        "id": "YKyZitD9jcbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.merge(name_grouped, name_grouped_aug, on='İsim', how='inner').sort_values(by= 'Gönderim Saati (AĞUSTOS)', ascending=False).reset_index(drop=True).to_excel('AGUSTOS_vakasini_gec_gonderen_personel.xlsx')"
      ],
      "metadata": {
        "id": "gUKmen0GfxRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fuol9rSYfxTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "73bOzAdYfxWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QybuC9atfxZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gRYty3cXfxbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JhwEOK26fxeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run find_district.py"
      ],
      "metadata": {
        "id": "iT8uARH-Sgdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa= find_district(df_avrupa)"
      ],
      "metadata": {
        "id": "vqKYf-x7SlJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[col for col in df_avrupa.columns]"
      ],
      "metadata": {
        "id": "TGScT6P6nlc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_aug= df10['Sheet1']"
      ],
      "metadata": {
        "id": "_95EjPBCrAXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_aug"
      ],
      "metadata": {
        "id": "46-jjSjYrDOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names= df_avrupa[[\"Ekipteki Kişiler\",\"İstasyon İçin Vaka Kapatma Süresi  (Vaka Veriliş - İlk KKM'ye gönderim)\"]]"
      ],
      "metadata": {
        "id": "blZBd7IHgN2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names= df_aug[[\"EKIPTEKI KISILER\",\"ISTASYON ICIN VAKA KAPATMA SURESI  (VAKA VERILIS   ILK KKM'YE GONDERIM)\"]]"
      ],
      "metadata": {
        "id": "CwRtvEYhtD2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names.rename(columns={\"Ekipteki Kişiler\": \"EKIPTEKI KISILER\"}, inplace=True)"
      ],
      "metadata": {
        "id": "mKYAO7GFpraM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names['EKIPTEKI KISILER']= df_names['EKIPTEKI KISILER'].fillna(0)"
      ],
      "metadata": {
        "id": "u9n-KxdJKaLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names= df_names[df_names['EKIPTEKI KISILER'] != 0]"
      ],
      "metadata": {
        "id": "7CsvWqVjKaOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names.columns= ['İsim', 'Gönderim Saati']\n",
        "df_names['aug_value']= 1"
      ],
      "metadata": {
        "id": "RP6d6e2_KaQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named df_names\n",
        "\n",
        "def convert_to_timedelta(time_str):\n",
        "    \"\"\"\n",
        "    Converts a time string in the format \"X Gün Y Saat Z Dakika\" to a pandas Timedelta.\n",
        "    \"\"\"\n",
        "    parts = time_str.split()\n",
        "    days = int(parts[0]) if parts[0].isdigit() else 0  # Handle cases where days are 0\n",
        "    hours = int(parts[2]) if len(parts) > 2 and parts[2].isdigit() else 0\n",
        "    minutes = int(parts[4]) if len(parts) > 4 and parts[4].isdigit() else 0\n",
        "\n",
        "    return pd.Timedelta(days=days, hours=hours, minutes=minutes)\n",
        "\n",
        "# Apply the function to the 'Gönderim Saati' column\n",
        "df_names['Gönderim Saati'] = df_names['Gönderim Saati'].apply(convert_to_timedelta)"
      ],
      "metadata": {
        "id": "fw-fLDP2kyfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names['Gönderim Saati']= df_names['Gönderim Saati'].dt.total_seconds()"
      ],
      "metadata": {
        "id": "FLoML2d6kyij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names['Gönderim Saati']= df_names['Gönderim Saati'] / 3600"
      ],
      "metadata": {
        "id": "C9keRy4Dkyk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_names['İsim']= df_names['İsim'].astype(str).str.split(',')\n",
        "df_names= df_names.explode('İsim')\n",
        "df_names= df_names[~(df_names['İsim'].astype(str).str.contains('Sürücü'))]\n",
        "df_names['İsim']= df_names['İsim'].astype(str).str.replace(' - Yardımcı Sağlık Personeli', '').astype(str).str.replace(' - Ekip Sorumlusu', '')\n",
        "df_names['İsim']= df_names['İsim'].astype(str).str.strip()"
      ],
      "metadata": {
        "id": "mKxrQ9bxkyna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times= df_names.groupby('İsim').agg({'Gönderim Saati':'mean', 'aug_value':'sum'}).reset_index().sort_values(by= 'Gönderim Saati', ascending=False)"
      ],
      "metadata": {
        "id": "h-K__sw2kypo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times.columns= ['İsim', 'aug_gonderim_saati', 'aug_value']"
      ],
      "metadata": {
        "id": "ku5LQhJWrRhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times['aug_gonderim_saati']= round(times['aug_gonderim_saati'],2)"
      ],
      "metadata": {
        "id": "XKgsg9mVsMlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times_all['Gönderim Saati']= round(times['Gönderim Saati'],2)"
      ],
      "metadata": {
        "id": "WDDIV52hkysA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times_all['Gönderim Saati']= times_all['Gönderim Saati'].fillna(0)"
      ],
      "metadata": {
        "id": "fNzNGi4CkyuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times_all.sort_values(by= 'Gönderim Saati', ascending=False)"
      ],
      "metadata": {
        "id": "cJFglF4ApDep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times_all.columns= ['İsim', 'Gönderim Saati(OCAK-TEMMUZ)', 'Sayı(OCAK-TEMMUZ)']"
      ],
      "metadata": {
        "id": "7ntxR5G0tqSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times"
      ],
      "metadata": {
        "id": "v6qdKgrYuRUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times_all"
      ],
      "metadata": {
        "id": "_G0n5EOquVFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times_names= pd.merge(times_all, times, on='İsim', how='inner')\n",
        "times_names.columns= ['İsim', 'Gönderim Saati(OCAK-TEMMUZ)', 'Sayı(OCAK-TEMMUZ)', 'Gönderim Saati(Ağustos)', 'Sayı(Ağustos)']\n"
      ],
      "metadata": {
        "id": "VJS-BOp9qQof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times_names[times_names['İsim']=='SEVİM UÇA']"
      ],
      "metadata": {
        "id": "JKQC5FTKuaxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times_names.sort_values(by= 'Gönderim Saati(Ağustos)', ascending=False).reset_index(drop=True).to_excel('vakasini_gec_gonderen_personel.xlsx')"
      ],
      "metadata": {
        "id": "_y6VxL-csVwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_aug= df10['Sheet1']"
      ],
      "metadata": {
        "id": "Ut6H6cNInUUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_aug"
      ],
      "metadata": {
        "id": "YYAJpKqpnUW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DjRaSuMmnUaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nexhBCLknUcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pKRzzlr9nUfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kZXM2xMKnUhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**YILLIK 270 SAAT EK MESAİYİ AŞMAYACAK ŞEKİLDE SÜRÜCÜ MESAİ HESAPLAMA**"
      ],
      "metadata": {
        "id": "KTnErIm2KbOH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x7Op5oOuKaTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa.drop(columns='BOLGE', inplace=True)"
      ],
      "metadata": {
        "id": "dhoIPGRBdi7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa['EKIPTEKI KISILER']= df_avrupa['EKIPTEKI KISILER'].str.split(',')"
      ],
      "metadata": {
        "id": "ef4xWYtasnMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa= df_avrupa.explode('EKIPTEKI KISILER')"
      ],
      "metadata": {
        "id": "4bNcvApqsnOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa['EKIPTEKI KISILER']= df_avrupa['EKIPTEKI KISILER'].fillna('-')"
      ],
      "metadata": {
        "id": "ARSwvWpvtTRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa= df_avrupa[df_avrupa['EKIPTEKI KISILER'].str.contains('Sürücü')]"
      ],
      "metadata": {
        "id": "AXx6wAKHsnRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa['EKIPTEKI KISILER']= df_avrupa['EKIPTEKI KISILER'].apply(lambda x: x.split(' - ')[0])"
      ],
      "metadata": {
        "id": "z1rlv0t6snTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa['EKIPTEKI KISILER']= df_avrupa['EKIPTEKI KISILER'].str.strip()"
      ],
      "metadata": {
        "id": "1Emv3-b3snWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa['VAKA VERILIS TARIH SAAT']"
      ],
      "metadata": {
        "id": "gJtuTrYBuKFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa['VAKA VERILIS TARIH SAAT']= df_avrupa['VAKA VERILIS TARIH SAAT'].dt.strftime('%Y-%m-%d')"
      ],
      "metadata": {
        "id": "gxf9NzbisnYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa"
      ],
      "metadata": {
        "id": "Mb4vwhrtu13y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa_grouped= df_avrupa.groupby(['EKIPTEKI KISILER', 'MANUEL SEF TARIHI']).agg({'Value':'sum'}).reset_index()"
      ],
      "metadata": {
        "id": "zcNbAerPsnac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivot= df_avrupa_grouped.pivot_table(index='EKIPTEKI KISILER', columns='MANUEL SEF TARIHI', values='Value', aggfunc='count').fillna(0)"
      ],
      "metadata": {
        "id": "botnJpo5ugeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivot['Toplam']= df_pivot.sum(axis=1)"
      ],
      "metadata": {
        "id": "aoDnDKHrvIpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivot.sort_values(by= 'Toplam', ascending=False)"
      ],
      "metadata": {
        "id": "fcFlrigHvIr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SÜRÜCÜ MESAİ HESAPLAMA SONU**"
      ],
      "metadata": {
        "id": "hpg-0ayyKlBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa"
      ],
      "metadata": {
        "id": "ny2J0BUevIt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations= pd.read_excel('C:/Users/mkaya/OneDrive/Masaüstü/istanbul112_hidden/data/locations/station_locations.xlsx')"
      ],
      "metadata": {
        "id": "6dA4yyumvIxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations.drop(columns='Unnamed: 0', inplace=True)"
      ],
      "metadata": {
        "id": "SD57Hwl3vIzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations"
      ],
      "metadata": {
        "id": "otIGo53svI19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: find district neighbourhood city based on lon lat of station_locations\n",
        "\n",
        "import requests\n",
        "\n",
        "def find_district_neighbourhood_city(latitude, longitude):\n",
        "  \"\"\"\n",
        "  Finds the district, neighbourhood, and city based on latitude and longitude.\n",
        "\n",
        "  Args:\n",
        "      lat: The latitude of the location.\n",
        "      lon: The longitude of the location.\n",
        "\n",
        "  Returns:\n",
        "      A dictionary containing the district, neighbourhood, and city.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    url = f\"https://nominatim.openstreetmap.org/reverse?format=json&lat={latitude}&lon={longitude}&zoom=18&addressdetails=1\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    address = data.get(\"address\", {})\n",
        "    district = address.get(\"suburb\") or address.get(\"city_district\") or address.get(\"county\")\n",
        "    neighbourhood = address.get(\"neighbourhood\")\n",
        "    city = address.get(\"city\") or address.get(\"town\") or address.get(\"village\")\n",
        "\n",
        "    return {\"district\": district, \"neighbourhood\": neighbourhood, \"city\": city}\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error fetching location data: {e}\")\n",
        "    return {\"district\": None, \"neighbourhood\": None, \"city\": None}\n",
        "\n",
        "\n",
        "# Apply the function to the station_locations DataFrame\n",
        "station_locations[[\"district\", \"neighbourhood\", \"city\"]] = station_locations.apply(\n",
        "    lambda row: pd.Series(find_district_neighbourhood_city(row[\"lat\"], row[\"lon\"])),\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "print(station_locations)\n"
      ],
      "metadata": {
        "id": "Ou-0UecpNPdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations.drop(columns='neighbourhood', inplace=True)"
      ],
      "metadata": {
        "id": "hsjHxeBzNPfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations['district'].fillna('-', inplace=True)"
      ],
      "metadata": {
        "id": "i7_mcZiwOz0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations['district']= station_locations['district'].apply(lambda x: x.split('Mahalle')[0])"
      ],
      "metadata": {
        "id": "ROoZl58SNPiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations['district']= station_locations['district'].str.strip()"
      ],
      "metadata": {
        "id": "mGF3yETuNPky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations['district']= station_locations['district'].apply(lambda x: x.replace('i','İ').replace('ı','I').replace('ö','Ö').replace('ü','Ü').replace('ş','Ş').replace('ç','Ç').replace('ğ','Ğ').replace('ý','I').replace('þ','Ş'))\n",
        "station_locations['city']= station_locations['city'].apply(lambda x: x.replace('i','İ').replace('ı','I').replace('ö','Ö').replace('ü','Ü').replace('ş','Ş').replace('ç','Ç').replace('ğ','Ğ').replace('ý','I').replace('þ','Ş'))"
      ],
      "metadata": {
        "id": "V_vB2fl-NPnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations['district']= station_locations['district'].str.upper()\n",
        "station_locations['city']= station_locations['city'].str.upper()"
      ],
      "metadata": {
        "id": "Q0blCYUBNPpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations['value']= 1"
      ],
      "metadata": {
        "id": "DMlIpd5qPVue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations.to_excel('C:/Users/mkaya/OneDrive/Masaüstü/istanbul112_hidden/data/locations/station_locations.xlsx')"
      ],
      "metadata": {
        "id": "z17uFOa7TyJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations"
      ],
      "metadata": {
        "id": "WPvyFMglT8Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lcbA7SGaT8cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N_ED6h5iT8eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Jq_a4PNT8hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyc_s2xgT8j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "POhR-mWrT8mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u0-o8XIUT8o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8fzIoABT8rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "district_counts= station_locations.groupby(['city', 'district'])['value'].sum().to_frame().reset_index().sort_values(by= ['city', 'value'], ascending= [True, False])"
      ],
      "metadata": {
        "id": "G0bpdsFWPVw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "district_counts"
      ],
      "metadata": {
        "id": "8mtCCeKJPVz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa= df_avrupa[df_avrupa['ILCE_ARGE'] != 'BELİRTİLMEMİŞ']"
      ],
      "metadata": {
        "id": "IJnoTLETPV2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "district_counts.columns= ['ILCE_ARGE', 'MAHALLE_ARGE', 'district_ambulance_count']"
      ],
      "metadata": {
        "id": "d9RMIFalScXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa= pd.merge(df_avrupa, district_counts, on= ['ILCE_ARGE', 'MAHALLE_ARGE'], how= 'inner')"
      ],
      "metadata": {
        "id": "SRFmmGoYPV46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa_ambulances= df_avrupa.groupby(['ILCE_ARGE', 'MAHALLE_ARGE']).agg({'Value':'sum', 'district_ambulance_count':'mean'}).reset_index()"
      ],
      "metadata": {
        "id": "GHc-Q0mlPV7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa_ambulances['total_score']=round( df_avrupa_ambulances['Value'] / df_avrupa_ambulances['district_ambulance_count'],2)"
      ],
      "metadata": {
        "id": "w-RexbaaPV9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa_ambulances.sort_values(by= 'total_score', ascending=False).head(50)"
      ],
      "metadata": {
        "id": "SkI2BRARS9o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa_ambulances.to_excel('df_avrupa_ambulances.xlsx')"
      ],
      "metadata": {
        "id": "kS1XLbuhS9rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa_ambulances_hourly= df_avrupa.groupby(['Ay', 'Gün', 'hour','ILCE_ARGE', 'MAHALLE_ARGE']).agg({'Value':'sum', 'district_ambulance_count':'mean'}).reset_index().sort_values(by='Value', ascending=False)"
      ],
      "metadata": {
        "id": "y8hHpHErS9vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa_ambulances_hourly['district_ambulance_count'].fillna(-1, inplace=True)"
      ],
      "metadata": {
        "id": "8KKw5hVhS9x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa_ambulances_hourly['total_score']=round( df_avrupa_ambulances_hourly['Value'] / df_avrupa_ambulances_hourly['district_ambulance_count'],2)"
      ],
      "metadata": {
        "id": "AsYj9F1JS90L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa_ambulances_hourly= df_avrupa_ambulances_hourly.sort_values(by= ['Ay', 'Gün', 'total_score'], ascending=[True, True, False])"
      ],
      "metadata": {
        "id": "tLjO3cIzS92q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa_ambulances_hourly[df_avrupa_ambulances_hourly['total_score'] != 0].to_excel('df_avrupa_ambulances_hourly.xlsx')"
      ],
      "metadata": {
        "id": "8Ep81chIS95A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YucK1VW1S98W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S1ELmcTpS9-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QDnMnZdcS-A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QO1lAgMJS-DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arnavutkoy= df_avrupa[df_avrupa['EKIP NO'].str.contains('ARN')]"
      ],
      "metadata": {
        "id": "F0f41ftDbraF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arnavutkoy"
      ],
      "metadata": {
        "id": "hy_PyydObrc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iM-7HyS-brfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KcwnasAAbriJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa['VAKA VERILIS\\nTARIHI']"
      ],
      "metadata": {
        "id": "_v5ApzmhbrmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa.head()"
      ],
      "metadata": {
        "id": "S_swTeG5-VMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_datetime(row):\n",
        "  try:\n",
        "    return pd.to_datetime(row, format= '%d-%m-%Y %H:%M:%S')\n",
        "  except:\n",
        "    try:\n",
        "      return pd.to_datetime(row, format= '%Y-%m-%d %H:%M:%S')\n",
        "    except:\n",
        "      return '-'\n",
        "\n",
        "def recalculate_reach(row):\n",
        "  if row['KENSEL/KIRSAL']=='KIRSAL':\n",
        "    row['reach_time']= row['reach_time'] / 3\n",
        "    return row['reach_time']\n",
        "  else:\n",
        "    return row['reach_time']\n",
        "\n",
        "def process_data(df):\n",
        "    df.columns = [col.strip().upper() for col in df.columns]\n",
        "\n",
        "    columns_list = []\n",
        "    for i in df.columns:\n",
        "        i = i.replace('-', ' ').replace('Ç', 'C').replace('Ğ', 'G').replace('İ', 'I').replace('Ö', 'O').replace('Ş', 'S').replace('Ü', 'U').strip()\n",
        "        columns_list.append(i)\n",
        "    df.columns = columns_list\n",
        "    print('Kolonlar dönüştürüldü.')\n",
        "\n",
        "    df['VAKA VERILIS TARIH SAAT']= df['VAKA VERILIS\\nTARIHI'] + ' ' + df['VAKA VERILIS\\nSAATI']\n",
        "    df['VAKA CIKIS TARIH SAAT'] = df['VAKAYA CIKIS TARIHI'] + ' '+ df['VAKAYA CIKIS SAATI']\n",
        "    df['OLAY YER VARIS TARIH SAAT']= df['OLAY YERI VARIS TARIHI'] + ' ' + df['OLAY YERI VARIS SAATI']\n",
        "\n",
        "    df.drop(columns=['VAKA VERILIS\\nTARIHI', 'VAKA VERILIS\\nSAATI', 'VAKAYA CIKIS TARIHI', 'VAKAYA CIKIS SAATI', 'OLAY YERI VARIS TARIHI', 'OLAY YERI VARIS SAATI'], inplace=True)\n",
        "\n",
        "    df['VAKA VERILIS TARIH SAAT'] = df['VAKA VERILIS TARIH SAAT'].apply(to_datetime)\n",
        "    df['VAKA CIKIS TARIH SAAT'] = df['VAKA CIKIS TARIH SAAT'].apply(to_datetime)\n",
        "    df['OLAY YER VARIS TARIH SAAT']= df['OLAY YER VARIS TARIH SAAT'].apply(to_datetime)\n",
        "\n",
        "    df['hour']= df['VAKA VERILIS TARIH SAAT'].dt.strftime('%H')\n",
        "\n",
        "    df['Gün'] = df['VAKA VERILIS TARIH SAAT'].dt.day_name(locale= 'tr_TR')\n",
        "    df['Gün']= df['Gün'].str.replace('i','İ').str.replace('ı','I').str.replace('ö','Ö').str.replace('ü','Ü').str.replace('ş','Ş').str.replace('ç','Ç').str.replace('ğ','Ğ').str.upper()\n",
        "    df['Gün']= df['Gün'].str.replace('ý','I').str.replace('þ','Ş')\n",
        "\n",
        "    df['Ay']= df['VAKA VERILIS TARIH SAAT'].dt.month\n",
        "    df['Yıl']= df['VAKA VERILIS TARIH SAAT'].dt.year\n",
        "\n",
        "    df['ulasim_suresi']= (df['OLAY YER VARIS TARIH SAAT'] - df['VAKA CIKIS TARIH SAAT']).dt.seconds\n",
        "    df['ulasim_suresi']= df['ulasim_suresi'].astype('float32')\n",
        "\n",
        "    day_of_week= ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA', 'CUMARTESİ', 'PAZAR']\n",
        "    df['Gün'] = pd.Categorical(df['Gün'], categories=day_of_week, ordered=True)\n",
        "\n",
        "    df['Value']= 1\n",
        "    df['Value']= df['Value'].astype(int)\n",
        "    df.rename(columns={'ulasim_suresi':'reach_time'}, inplace=True)\n",
        "\n",
        "    #df= df[((df['reach_time']<=3600) & (df['OLAY YER VARIS TARIH SAAT'] > df[\"VAKA CIKIS TARIH SAAT\"]))]\n",
        "    df['reach_time']= df['reach_time'].astype('float32')\n",
        "    df['reach_time']= df.apply(recalculate_reach, axis=1)\n",
        "\n",
        "    df['hour']= df['hour'].astype(int)\n",
        "    #df= df[(df['hour'] >= 10) & (df['hour']<22)]\n",
        "\n",
        "    return df\n",
        "\n",
        "df_avrupa= process_data(df_avrupa)"
      ],
      "metadata": {
        "id": "9cjFjcU2SwEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia['Gün']= df_asia['VAKA VERILIS TARIH SAAT'].dt.day_name(locale= 'tr_TR')\n",
        "df_asia['Gün']= df_asia['Gün'].apply(lambda x: x.replace('i','İ').replace('ı','I').replace('ö','Ö').replace('ü','Ü').replace('ş','Ş').replace('ç','Ç').replace('ğ','Ğ').replace('ý','I').replace('þ','Ş').upper())\n",
        "df_asia"
      ],
      "metadata": {
        "id": "g1fyFddZ-CK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa['Gün']= df_avrupa['VAKA VERILIS TARIH SAAT'].dt.day_name(locale= 'tr_TR')\n",
        "df_avrupa['Gün']= df_avrupa['Gün'].apply(lambda x: x.replace('i','İ').replace('ı','I').replace('ö','Ö').replace('ü','Ü').replace('ş','Ş').replace('ç','Ç').replace('ğ','Ğ').replace('ý','I').replace('þ','Ş').upper())\n",
        "df_avrupa.head()"
      ],
      "metadata": {
        "id": "a8MkZYxY-IGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia['weekend']= df_asia['Gün'].isin(['CUMARTESİ', 'PAZAR'])\n",
        "df_avrupa['weekend']= df_avrupa['Gün'].isin(['CUMARTESİ', 'PAZAR'])"
      ],
      "metadata": {
        "id": "agrIQAv09mJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa"
      ],
      "metadata": {
        "id": "4H7vAn-L9x0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia.groupby(['ADRES ILCE', 'MAHALLE','weekend']).agg({'VALUE':'sum'}).reset_index().sort_values(by=['ADRES ILCE', 'VALUE'], ascending=[True,False]).to_excel('df_asia_haftasonu.xlsx')\n",
        "df_avrupa.groupby(['ILCE_ARGE', 'MAHALLE_ARGE','weekend']).agg({'Value':'sum'}).reset_index().sort_values(by=['ILCE_ARGE', 'Value'], ascending=[True,False]).to_excel('df_avrupa_haftasonu.xlsx')\n"
      ],
      "metadata": {
        "id": "xKDhQiYM-SE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run find_district.py"
      ],
      "metadata": {
        "id": "8_Dx-mlvaJsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa= find_district(df_avrupa)"
      ],
      "metadata": {
        "id": "XCBDWAiSaL1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([col for col in df_avrupa.columns])"
      ],
      "metadata": {
        "id": "C7IOMIEgZ6Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k266IT5wdUDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa.groupby(['İLÇE_ARGE','MAHALLE_ARGE','GUN']).agg({'VALUE':'sum'}).reset_index().sort_values(by= ['GUN', 'VALUE'], ascending= [True, False]).to_excel('avrupa_gunluk_genel.xlsx')"
      ],
      "metadata": {
        "id": "YUHGyPv7dwS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa_grouped= df_avrupa.groupby(['İLÇE_ARGE','MAHALLE_ARGE','AY','GUN']).agg({'VALUE':'sum'}).reset_index().sort_values(by= ['İLÇE_ARGE', 'VALUE'], ascending= [True, False])\n",
        "df_avrupa_grouped= df_avrupa_grouped[df_avrupa_grouped['VALUE'] != 0]\n",
        "df_avrupa_grouped.to_excel('avrupa_aylik_günlük.xlsx')"
      ],
      "metadata": {
        "id": "hIt1MKmldwV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa_grouped"
      ],
      "metadata": {
        "id": "9x8o8nXxdwZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ISv6mRMdwbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ki3Dyc9wcPgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa.groupby(['ILCE_ARGE', 'MAHALLE_ARGE'])['Value'].sum().to_frame().reset_index().sort_values(by= ['ILCE_ARGE', 'Value'], ascending= [True, False]).to_excel('Vaka Sayıları.xlsx')"
      ],
      "metadata": {
        "id": "HhUUhbl3SwHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q7PrloyJSwJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-lX8ORIwSwLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gVGzubRmSwOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([name for col in df_avrupa.columns for name in col if 'Adres İlçe' in name.lower()])"
      ],
      "metadata": {
        "id": "bSak8LVOKFTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa= df_avrupa[['Vakanın Enlemi', 'Vakanın Boylamı','Vaka Veriliş\\nTarihi','Vaka Veriliş\\nSaati','Vakaya Çıkış Tarihi','İhbar Adresi','Vakaya Çıkış Saati','Olay Yeri Varış Tarihi','Olay Yeri Varış Saati','Kensel/Kırsal', 'BOLGE']]"
      ],
      "metadata": {
        "id": "zZSVDFPmqiaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia= df_asia[['Vakanın Enlemi', 'Vakanın Boylamı','Vaka Veriliş\\nTarihi','Vaka Veriliş\\nSaati','Vakaya Çıkış Tarihi','Vakaya Çıkış Saati','Olay Yeri Varış Tarihi','Olay Yeri Varış Saati','Kensel/Kırsal', 'BOLGE']]"
      ],
      "metadata": {
        "id": "KA8hOaYXHF9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa[df_avrupa['Vakanın Enlemi'] != '-'].head()"
      ],
      "metadata": {
        "id": "Q0smTTlfIcaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df= df[['Vakanın Enlemi', 'Vakanın Boylamı','Vaka Veriliş\\nTarihi','Vaka Veriliş\\nSaati','Vakaya Çıkış Tarihi','Vakaya Çıkış Saati','Olay Yeri Varış Tarihi','Olay Yeri Varış Saati','Kensel/Kırsal']]\n",
        "#df_asia= df_asia[['Vakanın Enlemi', 'Vakanın Boylamı','Vaka Veriliş\\nTarihi','Vaka Veriliş\\nSaati','Vakaya Çıkış Tarihi','Vakaya Çıkış Saati','Olay Yeri Varış Tarihi','Olay Yeri Varış Saati','Kensel/Kırsal']]"
      ],
      "metadata": {
        "id": "0w_6rvMbndXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa= df_avrupa[~df_avrupa['Vakaya Çıkış Tarihi'].isna()]"
      ],
      "metadata": {
        "id": "dZ79Fe36rAen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia= df_asia[~df_asia['Vakaya Çıkış Tarihi'].isna()]"
      ],
      "metadata": {
        "id": "wRFi5FZmHNrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Vaka Veriliş\\nTarihi'].isna()]"
      ],
      "metadata": {
        "id": "WzdPWFK9rJrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa"
      ],
      "metadata": {
        "id": "HWIaA0__Mnf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([col for col in df.keys()])"
      ],
      "metadata": {
        "id": "X3kXVZX6AmMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa.drop(columns='BOLGE', inplace=True)"
      ],
      "metadata": {
        "id": "G014gZGiY2RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa['BOLGE']= 'Avrupa'"
      ],
      "metadata": {
        "id": "YfsegapkY97u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_datetime(row):\n",
        "  try:\n",
        "    return pd.to_datetime(row, format= '%d-%m-%Y %H:%M:%S')\n",
        "  except:\n",
        "    try:\n",
        "      return pd.to_datetime(row, format= '%Y-%m-%d %H:%M:%S')\n",
        "    except:\n",
        "      return '-'\n",
        "\n",
        "def recalculate_reach(row):\n",
        "  if row['KENSEL/KIRSAL']=='KIRSAL':\n",
        "    row['reach_time']= row['reach_time'] / 3\n",
        "    return row['reach_time']\n",
        "  else:\n",
        "    return row['reach_time']\n",
        "\n",
        "def process_data(df):\n",
        "    df.columns = [col.strip().upper() for col in df.columns]\n",
        "\n",
        "    columns_list = []\n",
        "    for i in df.columns:\n",
        "        i = i.replace('-', ' ').replace('Ç', 'C').replace('Ğ', 'G').replace('İ', 'I').replace('Ö', 'O').replace('Ş', 'S').replace('Ü', 'U').strip()\n",
        "        columns_list.append(i)\n",
        "    df.columns = columns_list\n",
        "    print('Kolonlar dönüştürüldü.')\n",
        "\n",
        "    df['VAKA VERILIS TARIH SAAT']= df['VAKA VERILIS\\nTARIHI'] + ' ' + df['VAKA VERILIS\\nSAATI']\n",
        "    df['VAKA CIKIS TARIH SAAT'] = df['VAKAYA CIKIS TARIHI'] + ' '+ df['VAKAYA CIKIS SAATI']\n",
        "    df['OLAY YER VARIS TARIH SAAT']= df['OLAY YERI VARIS TARIHI'] + ' ' + df['OLAY YERI VARIS SAATI']\n",
        "\n",
        "    df.drop(columns=['VAKA VERILIS\\nTARIHI', 'VAKA VERILIS\\nSAATI', 'VAKAYA CIKIS TARIHI', 'VAKAYA CIKIS SAATI', 'OLAY YERI VARIS TARIHI', 'OLAY YERI VARIS SAATI'], inplace=True)\n",
        "\n",
        "    df['VAKA VERILIS TARIH SAAT'] = df['VAKA VERILIS TARIH SAAT'].apply(to_datetime)\n",
        "    df['VAKA CIKIS TARIH SAAT'] = df['VAKA CIKIS TARIH SAAT'].apply(to_datetime)\n",
        "    df['OLAY YER VARIS TARIH SAAT']= df['OLAY YER VARIS TARIH SAAT'].apply(to_datetime)\n",
        "\n",
        "    df['hour']= df['VAKA VERILIS TARIH SAAT'].dt.strftime('%H')\n",
        "\n",
        "    df['Gün'] = df['VAKA VERILIS TARIH SAAT'].dt.day_name(locale= 'tr_TR')\n",
        "    df['Gün']= df['Gün'].str.replace('i','İ').str.replace('ı','I').str.replace('ö','Ö').str.replace('ü','Ü').str.replace('ş','Ş').str.replace('ç','Ç').str.replace('ğ','Ğ').str.upper()\n",
        "    df['Gün']= df['Gün'].str.replace('ý','I').str.replace('þ','Ş')\n",
        "\n",
        "    df['Ay']= df['VAKA VERILIS TARIH SAAT'].dt.month\n",
        "    df['Yıl']= df['VAKA VERILIS TARIH SAAT'].dt.year\n",
        "\n",
        "    df['ulasim_suresi']= (df['OLAY YER VARIS TARIH SAAT'] - df['VAKA CIKIS TARIH SAAT']).dt.seconds\n",
        "    df['ulasim_suresi']= df['ulasim_suresi'].astype('float32')\n",
        "\n",
        "    day_of_week= ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA', 'CUMARTESİ', 'PAZAR']\n",
        "    df['Gün'] = pd.Categorical(df['Gün'], categories=day_of_week, ordered=True)\n",
        "\n",
        "    df['Value']= 1\n",
        "    df['Value']= df['Value'].astype(int)\n",
        "    df.rename(columns={'ulasim_suresi':'reach_time'}, inplace=True)\n",
        "\n",
        "    df= df[((df['reach_time']<=3600) & (df['OLAY YER VARIS TARIH SAAT'] > df[\"VAKA CIKIS TARIH SAAT\"]))]\n",
        "    df['reach_time']= df['reach_time'].astype('float32')\n",
        "    df['reach_time']= df.apply(recalculate_reach, axis=1)\n",
        "\n",
        "    df['hour']= df['hour'].astype(int)\n",
        "    df= df[(df['hour'] >= 10) & (df['hour']<22)]\n",
        "\n",
        "    df['Ay']= df['Ay'].astype(int)\n",
        "    df['Gün']= df['Gün'].str.strip()\n",
        "    df['hour']= df['hour'].astype(int)\n",
        "\n",
        "    df= df[df['VAKANIN ENLEMI'] != '-']\n",
        "    df= df[df['VAKANIN BOYLAMI'] != '-']\n",
        "    df['VAKANIN ENLEMI']= df['VAKANIN ENLEMI'].astype('float32')\n",
        "    df['VAKANIN BOYLAMI']= df['VAKANIN BOYLAMI'].astype('float32')\n",
        "\n",
        "    # Initialize MinMaxScaler\n",
        "    scaler = MinMaxScaler(feature_range=(1, 100))\n",
        "\n",
        "    # Apply log transformation and scaling within each group\n",
        "    df['reach_time_log'] = df.groupby(['BOLGE', 'Ay', 'Gün'])['reach_time'].transform(lambda x: np.log1p(x))\n",
        "    df['reach_time_scaled'] = df.groupby(['BOLGE', 'Ay', 'Gün'])['reach_time_log'].transform(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)).flatten())\n",
        "    df.drop(columns='reach_time_log', inplace=True)\n",
        "    df.rename(columns={'Value':'case_count'}, inplace=True)\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    return df\n",
        "df_eu_converted= process_data(df_avrupa)\n",
        "#df_asia_converted= process_data(df_asia)"
      ],
      "metadata": {
        "id": "hnX1nbdClyKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_eu_converted"
      ],
      "metadata": {
        "id": "kAwXfyhBQO90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia_converted= df_asia.copy()"
      ],
      "metadata": {
        "id": "RG1mKy_XUrAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia_converted['Gün']= df_asia_converted['VAKA VERILIS TARIH SAAT'].dt.day_name(locale= 'tr_TR')\n",
        "df_asia_converted['Gün']= df_asia_converted['Gün'].apply(lambda x: x.replace('i','İ').replace('ı','I').replace('ö','Ö').replace('ü','Ü').replace('ş','Ş').replace('ç','Ç').replace('ğ','Ğ').replace('ý','I').replace('þ','Ş').upper())\n",
        "df_asia_converted"
      ],
      "metadata": {
        "id": "yPgWjLnVHyve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_eu_converted['Gün']= df_eu_converted['VAKA VERILIS TARIH SAAT'].dt.day_name(locale= 'tr_TR')\n",
        "df_eu_converted['Gün']= df_eu_converted['Gün'].apply(lambda x: x.replace('i','İ').replace('ı','I').replace('ö','Ö').replace('ü','Ü').replace('ş','Ş').replace('ç','Ç').replace('ğ','Ğ').replace('ý','I').replace('þ','Ş').upper())\n",
        "df_eu_converted"
      ],
      "metadata": {
        "id": "Px_DZp0DGzVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa"
      ],
      "metadata": {
        "id": "LTeQpzR6YD9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia_converted.drop(columns='BOLGE', inplace=True)"
      ],
      "metadata": {
        "id": "SjgRsvl2UxyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([col for col in df_asia_converted.columns])"
      ],
      "metadata": {
        "id": "1s9vbdTEXInF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia_converted.groupby(['ADRES ILCE', 'MAHALLE','Ay', 'Gün']).agg({'case_count':'sum'}).reset_index().sort_values(by=['ADRES ILCE', 'case_count'], ascending=[True,False]).to_excel('df_asia_converted.xlsx')"
      ],
      "metadata": {
        "id": "qACiDGd7W_Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia_converted.groupby(['ADRES ILCE', 'MAHALLE', 'Gün']).agg({'case_count':'sum'}).reset_index().sort_values(by=['ADRES ILCE', 'case_count'], ascending=[True,False]).to_excel('df_asia_gunluk_genel.xlsx')"
      ],
      "metadata": {
        "id": "8wq43aGdhxfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_asia_converted['BOLGE']= 'ASYA'"
      ],
      "metadata": {
        "id": "qZJJ3e13U4qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(1, 100))\n",
        "df_asia_converted['reach_time_log'] = df_asia_converted.groupby(['BOLGE', 'Ay', 'Gün'])['reach_time'].transform(lambda x: np.log1p(x))\n",
        "df_asia_converted['reach_time_scaled'] = df_asia_converted.groupby(['BOLGE', 'Ay', 'Gün'])['reach_time_log'].transform(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)).flatten())\n",
        "df_asia_converted.drop(columns='reach_time_log', inplace=True)\n",
        "df_asia_converted.rename(columns={'Value':'case_count'}, inplace=True)\n",
        "df_asia_converted.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "4S37zmKhJXD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(1, 100))\n",
        "df_eu_converted['reach_time_log'] = df_eu_converted.groupby(['BOLGE', 'Ay', 'Gün'])['reach_time'].transform(lambda x: np.log1p(x))\n",
        "df_eu_converted['reach_time_scaled'] = df_eu_converted.groupby(['BOLGE', 'Ay', 'Gün'])['reach_time_log'].transform(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)).flatten())\n",
        "df_eu_converted.drop(columns='reach_time_log', inplace=True)\n",
        "df_eu_converted.rename(columns={'Value':'case_count'}, inplace=True)\n",
        "df_eu_converted.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "SPci_YdVJXGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_converted="
      ],
      "metadata": {
        "id": "MQwo25CFU9IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_converted= pd.concat([df_asia_converted, df_eu_converted])"
      ],
      "metadata": {
        "id": "OhFpqns8JXIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_converted"
      ],
      "metadata": {
        "id": "KLs6JcbIJXK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_reach_times(df_converted, w1_case_count, w2_mean_reach_time_scaled, w3_mean_reach_time):\n",
        "\n",
        "  # Group by 'BOLGE', 'ILCE_ARGE', 'MAHALLE_ARGE' and 'Gün'\n",
        "  grouped_df = df_converted.groupby(['BOLGE', 'ILCE_ARGE', 'MAHALLE_ARGE', 'Ay','Gün'])\n",
        "\n",
        "  # Initialize an empty list to collect the results\n",
        "  optimized_result_list = []\n",
        "\n",
        "  # Iterate over each group\n",
        "  for name, group in grouped_df:\n",
        "      # Calculate the mean reach_time_scaled for the day\n",
        "      daily_mean_reach_time_scaled = group['reach_time_scaled'].mean()\n",
        "\n",
        "      # Filter the group to only include rows where reach_time_scaled is greater than the daily mean\n",
        "      above_mean_hours = group[group['reach_time_scaled'] > daily_mean_reach_time_scaled].sort_values('hour')\n",
        "\n",
        "      # If there are no hours above the mean or less than 4, skip this group\n",
        "      if len(above_mean_hours) < 4:\n",
        "          continue\n",
        "\n",
        "      # Find all consecutive above mean hours sequences\n",
        "      start_idx = 0\n",
        "      while start_idx < len(above_mean_hours):\n",
        "          # Initialize the end of the consecutive hours\n",
        "          end_idx = start_idx\n",
        "\n",
        "          # Check for consecutive hours\n",
        "          while end_idx + 1 < len(above_mean_hours) and above_mean_hours.iloc[end_idx + 1]['hour'] == above_mean_hours.iloc[end_idx]['hour'] + 1:\n",
        "              end_idx += 1\n",
        "\n",
        "          # Check if the length of consecutive hours is at least 4\n",
        "          if end_idx - start_idx + 1 >= 4:\n",
        "              # Get the reach time and case count values for this interval\n",
        "              interval_hours = above_mean_hours.iloc[start_idx:end_idx + 1]\n",
        "              total_case_count = interval_hours['case_count'].sum()\n",
        "              mean_reach_time_scaled= interval_hours['reach_time_scaled'].mean()\n",
        "              mean_reach_time= interval_hours['reach_time'].mean()\n",
        "\n",
        "              # Append result to the list\n",
        "              optimized_result_list.append({\n",
        "                  'BOLGE': name[0],\n",
        "                  'ILCE_ARGE': name[1],\n",
        "                  'MAHALLE_ARGE': name[2],\n",
        "                  'Ay': name[3],\n",
        "                  'Gün':name[4],\n",
        "                  'consecutive_hour_interval': f\"{interval_hours.iloc[0]['hour']}-{interval_hours.iloc[-1]['hour']}\",\n",
        "                  'total_case_count': total_case_count,\n",
        "                  'mean_reach_time_scaled': mean_reach_time_scaled,\n",
        "                  'mean_reach_time': mean_reach_time\n",
        "              })\n",
        "\n",
        "          # Move to the next potential sequence\n",
        "          start_idx = end_idx + 1\n",
        "\n",
        "  # Convert the result list into a DataFrame\n",
        "  optimized_result_df = pd.DataFrame(optimized_result_list)\n",
        "  optimized_result_df['mean_reach_time_scaled']= round(optimized_result_df['mean_reach_time_scaled'].astype(float), 2)\n",
        "  optimized_result_df['mean_reach_time']= round(optimized_result_df['mean_reach_time'].astype(float), 2)\n",
        "\n",
        "\n",
        "  new_df= optimized_result_df.copy()\n",
        "  # Group by 'Gün' and apply scoring separately for each day\n",
        "  scored_result_list = []\n",
        "\n",
        "  # Iterate over each day in the dataset\n",
        "  for (month_name,day_name), day_group in new_df.groupby(['Ay','Gün']):\n",
        "      # Calculate the maximum values for normalization within the day\n",
        "      max_case_count_day = day_group['total_case_count'].max()\n",
        "      max_reach_time_scaled_day = day_group['mean_reach_time_scaled'].max()\n",
        "      max_reach_time_day = day_group['mean_reach_time'].max()\n",
        "      total_case_count= day_group['total_case_count'].sum()\n",
        "\n",
        "      # Calculate the score for each row based on the formula\n",
        "      day_group['score'] = (\n",
        "          w1_case_count * (day_group['total_case_count'] / (total_case_count)) +\n",
        "          w2_mean_reach_time_scaled * (1 - (day_group['mean_reach_time_scaled'] / max_reach_time_scaled_day)) +\n",
        "          w3_mean_reach_time * (1 - (day_group['mean_reach_time'] / max_reach_time_day))\n",
        "      )\n",
        "\n",
        "      # Append the scored group to the result list\n",
        "      scored_result_list.append(day_group)\n",
        "\n",
        "  # Concatenate the scored results for all days\n",
        "  scored_result_df = pd.concat(scored_result_list)\n",
        "\n",
        "  minmax_scaled_data= []\n",
        "  for (month_name,day_name), day_group in scored_result_df.groupby(['Ay','Gün']):\n",
        "    minmax_scaled_data.append(MinMaxScaler(feature_range=(1, 100)).fit_transform(day_group['score'].values.reshape(-1, 1)))\n",
        "\n",
        "  scored_result_df['score']= np.concatenate(minmax_scaled_data)\n",
        "  day_of_week= ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA', 'CUMARTESİ', 'PAZAR']\n",
        "  scored_result_df['Gün'] = pd.Categorical(scored_result_df['Gün'], categories=day_of_week, ordered=True)\n",
        "  scored_result_df.sort_values(by=['Gün', 'score'], ascending=[True, False], inplace=True)\n",
        "  scored_result_df.reset_index(drop=True, inplace=True)\n",
        "  scored_result_df.drop(columns=['scaled_score']).rename(columns={'consecutive_hour_interval':'Aralıksız Yoğunluk Süresi', 'total_case_count':'Toplam Vaka Sayısı', 'mean_reach_time_scaled':'Aralık Ortalama Ulaşım Gecikme Puanı', 'mean_reach_time':'Ortalama Ulaşım Süresi', 'score':'Katsayılı Gecikme Puanı'})#.to_excel('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/unfinished_works/hourly_district_reach_times/consecutive_hours_scores.xlsx')\n",
        "\n",
        "  return scored_result_df\n",
        "scored_results= optimize_reach_times(df_converted, 0.3, 0.4, 0.5)"
      ],
      "metadata": {
        "id": "LB6Yug9TOpVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cMvZV9pQJn3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_converted.to_csv('C:/Users/mkaya/OneDrive/Masaüstü/istanbul112_hidden/unfinished_works/df_converted.csv')"
      ],
      "metadata": {
        "id": "yfAjtk3YSmlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_converted= pd.read_csv('C:/Users/mkaya/OneDrive/Masaüstü/istanbul112_hidden/unfinished_works/df_converted.csv')"
      ],
      "metadata": {
        "id": "C2LuqxulVzo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_densities= df_converted.sort_values(by= ['Ay', 'Gün', 'hour', 'ILCE_ARGE', 'MAHALLE_ARGE'])[['ILCE_ARGE', 'MAHALLE_ARGE', 'Ay','Gün','hour','reach_time','reach_time_scaled','reach_time_mean']]"
      ],
      "metadata": {
        "id": "h1CfQ6kFVzwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_densities.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "ak4Qr_QuVzyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_densities.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "qKARBqzgb8q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xgNsCGbHBlO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_densities.sort_values(by=['ILCE_ARGE', 'MAHALLE_ARGE','Ay','Gün','hour'], ascending=True, inplace=True)"
      ],
      "metadata": {
        "id": "tIv4uoiHb8tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_densities.sort_values(by=['Ay', 'Gün', 'hour', 'ILCE_ARGE', 'MAHALLE_ARGE'], ascending=True, inplace=True)"
      ],
      "metadata": {
        "id": "5K3RfTaVb8vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_densities"
      ],
      "metadata": {
        "id": "FGaDWQocs381"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_densities.to_excel('avrupa_densities.xlsx')"
      ],
      "metadata": {
        "id": "7bYXg4zub8yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_densities= pd.read_excel('densities.xlsx')"
      ],
      "metadata": {
        "id": "b85AgKgnpUwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_densities.drop(columns='Unnamed: 0', inplace=True)"
      ],
      "metadata": {
        "id": "ygA5ymbxocHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_densities"
      ],
      "metadata": {
        "id": "_HEQ8N72piDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Group by Ay, Gün, MAHALLE_ARGE, ILCE_ARGE\n",
        "grouped_df = df_densities.groupby(['Ay', 'Gün', 'MAHALLE_ARGE', 'ILCE_ARGE'])\n",
        "\n",
        "# Initialize an empty list to collect the results\n",
        "optimized_result_list_with_mean = []\n",
        "\n",
        "# Iterate over each group\n",
        "for name, group in grouped_df:\n",
        "    # Sort the group by hour\n",
        "    group_sorted = group.sort_values('hour')\n",
        "\n",
        "    # Extract the hours where reach_time_mean is True\n",
        "    true_hours = group_sorted[group_sorted['reach_time_mean'] == True][['hour', 'reach_time', 'reach_time_scaled', 'cases']]\n",
        "\n",
        "    # If there are no true hours or less than 4, skip this group\n",
        "    if len(true_hours) < 4:\n",
        "        continue\n",
        "\n",
        "    # Find all consecutive True hours sequences\n",
        "    start_idx = 0\n",
        "    while start_idx < len(true_hours):\n",
        "        # Initialize the end of the consecutive hours\n",
        "        end_idx = start_idx\n",
        "\n",
        "        # Check for consecutive hours\n",
        "        while end_idx + 1 < len(true_hours) and true_hours.iloc[end_idx + 1]['hour'] == true_hours.iloc[end_idx]['hour'] + 1:\n",
        "            end_idx += 1\n",
        "\n",
        "        # Check if the length of consecutive hours is at least 4\n",
        "        if end_idx - start_idx + 1 >= 4:\n",
        "            # Get the reach time and case values for this interval\n",
        "            interval_hours = true_hours.iloc[start_idx:end_idx + 1]\n",
        "            reach_time_values = list(interval_hours['reach_time'])\n",
        "            mean_reach_time = interval_hours['reach_time'].mean()\n",
        "            mean_reach_time_scaled = interval_hours['reach_time_scaled'].mean()\n",
        "            mean_cases = interval_hours['cases'].mean()  # Calculate mean of cases in this interval\n",
        "\n",
        "            optimized_result_list_with_mean.append({\n",
        "                'Ay': name[0],\n",
        "                'Gün': name[1],\n",
        "                'MAHALLE_ARGE': name[2],\n",
        "                'ILCE_ARGE': name[3],\n",
        "                'consecutive_hour_interval': f\"{interval_hours.iloc[0]['hour']}-{interval_hours.iloc[-1]['hour']}\",\n",
        "                'reach_time_values': reach_time_values,\n",
        "                'mean_reach_time': mean_reach_time,\n",
        "                'mean_reach_time_scaled': mean_reach_time_scaled,\n",
        "                'mean_cases': mean_cases  # Add mean cases to the result\n",
        "            })\n",
        "\n",
        "        # Move to the next potential sequence\n",
        "        start_idx = end_idx + 1\n",
        "\n",
        "# Convert the result list into a DataFrame\n",
        "optimized_result_df_with_mean = pd.DataFrame(optimized_result_list_with_mean)\n",
        "\n",
        "# Save the result to an Excel file\n",
        "optimized_output_file_with_mean_path = 'avrupa_filtered_consecutive_hours_with_mean_reach_time.xlsx'\n",
        "optimized_result_df_with_mean.to_excel(optimized_output_file_with_mean_path, index=False)\n"
      ],
      "metadata": {
        "id": "ebDz37AnHgkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Group by Ay, Gün, MAHALLE_ARGE, ILCE_ARGE\n",
        "grouped_df = df_densities.groupby(['Ay', 'Gün', 'MAHALLE_ARGE', 'ILCE_ARGE'])\n",
        "\n",
        "# Initialize an empty list to collect the results\n",
        "optimized_result_list_with_mean = []\n",
        "\n",
        "# Iterate over each group\n",
        "for name, group in grouped_df:\n",
        "    # Sort the group by hour\n",
        "    group_sorted = group.sort_values('hour')\n",
        "\n",
        "    # Extract the hours where reach_time_mean is True\n",
        "    true_hours = group_sorted[group_sorted['reach_time_mean'] == True][['hour', 'reach_time', 'reach_time_scaled']]\n",
        "\n",
        "    # Check if there are at least 4 consecutive hours with True\n",
        "    if len(true_hours) >= 4:\n",
        "        for i in range(len(true_hours) - 3):\n",
        "            if true_hours.iloc[i + 3]['hour'] - true_hours.iloc[i]['hour'] == 3:  # Check for 4 consecutive hours\n",
        "                reach_time_values = list(true_hours['reach_time'])\n",
        "                mean_reach_time = true_hours['reach_time'].mean()  # Calculate the mean reach time for the interval\n",
        "                mean_reach_time_scaled= true_hours['reach_time_scaled'].mean()\n",
        "                optimized_result_list_with_mean.append({\n",
        "                    'Ay': name[0],\n",
        "                    'Gün': name[1],\n",
        "                    'MAHALLE_ARGE': name[2],\n",
        "                    'ILCE_ARGE': name[3],\n",
        "                    'consecutive_hour_interval': f\"{true_hours.iloc[i]['hour']}-{true_hours.iloc[i + 3]['hour']}\",\n",
        "                    'reach_time_values': reach_time_values,\n",
        "                    'mean_reach_time': mean_reach_time,\n",
        "                    'mean_reach_time_scaled': mean_reach_time_scaled\n",
        "                })\n",
        "                break  # Once we find 4 consecutive hours, no need to check further in this group\n",
        "\n",
        "# Convert the result list into a DataFrame\n",
        "optimized_result_df_with_mean = pd.DataFrame(optimized_result_list_with_mean)\n",
        "\n",
        "# Save the result to an Excel file\n",
        "optimized_output_file_with_mean_path = 'avrupa_filtered_consecutive_hours_with_mean_reach_time.xlsx'\n",
        "optimized_result_df_with_mean.to_excel(optimized_output_file_with_mean_path, index=False)"
      ],
      "metadata": {
        "id": "6paHui4ab8z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### A MORE EFFICIENT WAY\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def check_consecutive(group):\n",
        "    # Sort by hour to ensure hours are in sequence\n",
        "    group = group.sort_values('hour')\n",
        "\n",
        "    # Use rolling to check for 4 consecutive True values in reach_time_mean\n",
        "    group['consecutive_true'] = group['reach_time_mean'].rolling(window=4).sum() == 4\n",
        "\n",
        "    # If there are any 4 consecutive True values, find the first occurrence\n",
        "    if group['consecutive_true'].any():\n",
        "        start_idx = group['consecutive_true'].idxmax() - 3  # First of the 4-hour window\n",
        "        end_idx = start_idx + 3\n",
        "        consecutive_hours = f\"{group.loc[start_idx, 'hour']}-{group.loc[end_idx, 'hour']}\"\n",
        "        reach_time_values = group.loc[start_idx:end_idx, 'reach_time'].tolist()\n",
        "        mean_reach_time = group.loc[start_idx:end_idx, 'reach_time'].mean()\n",
        "        return pd.Series({\n",
        "            'consecutive_hour_interval': consecutive_hours,\n",
        "            'reach_time_values': reach_time_values,\n",
        "            'mean_reach_time': mean_reach_time\n",
        "        })\n",
        "    else:\n",
        "        return pd.Series({\n",
        "            'consecutive_hour_interval': None,\n",
        "            'reach_time_values': None,\n",
        "            'mean_reach_time': None\n",
        "        })\n",
        "\n",
        "# Apply the check_consecutive function to each group\n",
        "result = df_densities.groupby(['Ay', 'Gün', 'MAHALLE_ARGE', 'ILCE_ARGE']).apply(check_consecutive).dropna()\n",
        "\n",
        "# Save the result to an Excel file\n",
        "result.to_excel('avrupa_optimized_filtered_consecutive_hours_with_mean_reach_time.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "X27GJ6SpVEUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L8hapzlhVEWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_of_week= ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA', 'CUMARTESİ', 'PAZAR']\n",
        "optimized_result_df_with_mean['Gün'] = pd.Categorical(optimized_result_df_with_mean['Gün'], categories=day_of_week, ordered=True)"
      ],
      "metadata": {
        "id": "7YZ1EiJIkNU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_result_df_with_mean=optimized_result_df_with_mean.sort_values(by= ['Ay', 'Gün', 'ILCE_ARGE', 'MAHALLE_ARGE', 'consecutive_hour_interval'], ascending=[True, True, True, True, True])"
      ],
      "metadata": {
        "id": "WQQjHBNmj1Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_result_df_with_mean['mean_reach_time']= round(optimized_result_df_with_mean['mean_reach_time'].astype('float32'), 2)"
      ],
      "metadata": {
        "id": "ZREOyG8akdxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_result_df_with_mean.drop(columns='reach_time_values', inplace=True)"
      ],
      "metadata": {
        "id": "DECEKfQQkdzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_result_df_with_mean.to_excel('anadolu_filtered_consecutive_hours_with_mean_reach_time.xlsx')"
      ],
      "metadata": {
        "id": "aIXxALbXkd17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sH_S5nRkkd31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "drKLqTIGkd6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vVMJePU_kd8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_densities.head(10).to_excel('test.xlsx')"
      ],
      "metadata": {
        "id": "45689LawVz0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by month, day, and MAHALLE_ARGE to check for at least 4 hours with reach_time_mean being True\n",
        "result = df_converted.groupby(['Ay', 'Gün', 'MAHALLE_ARGE']).apply(\n",
        "    lambda group: (group['reach_time_mean'] == True).sum() >= 4\n",
        ").reset_index(name='at_least_4_hours')\n",
        "\n",
        "# Filter the result to only show neighborhoods where the condition is met\n",
        "filtered_result = result[result['at_least_4_hours'] == True]\n",
        "\n",
        "# Display the result\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Filtered Result\", dataframe=filtered_result)\n"
      ],
      "metadata": {
        "id": "uBp5NSADY67L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_densities.to_excel('densities.xlsx')"
      ],
      "metadata": {
        "id": "fIqjZlhxY69m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MvzL9ydiY7AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "f4TQuzWGY7CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QDO0SMJLY7FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "817FivXuY7HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cP0UN_9GY7JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9QiT6CJwVz2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k8Ize5VuVz5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run find_district.py"
      ],
      "metadata": {
        "id": "5rRZC7aWiBwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= find_district(df)"
      ],
      "metadata": {
        "id": "Mb24bF1qvAvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rural_new= {\n",
        "    'SARIYER': 'BAHÇEKÖY, DEMİRCİKÖY, GARİPÇE, GÜMÜŞDERE, KISIRKAYA, KUMKÖY, RUMELİFENERİ, USKUMRU, ZEKERİYE',\n",
        "    'ARNAVUTKÖY': 'BAKLALI, BALABAN, BOYALIK, ÇİLİNGİR, DURSUNKÖY, HACIMAŞLI, KARABURUN, SAZLIBOSNA, TAYAKADIN, YASSIÖREN, YENİKÖY, YEŞİLBAYIR',\n",
        "    'ÇATALCA': 'ATATÜRK, AKALAN, AYDINLAR, BAHŞAYİŞ, BAŞAK, BELGRAT, CELEPKÖY, ÇAKIL, ÇANAKÇA, ÇİFTLİKKÖY, DAĞYENİCE, ELBASAN, FATİH, GÖKÇEALİ, GÜMÜŞPINAR, HALLAÇLI, HİSARBEYLİ, İHSANİYE (MERKEZ VE PINARCA MEVKİİ), İNCEĞİZ, İZZETTİN, KABAKÇA, KALFA, KARACAKÖY MERKEZ, KARAMANDERE, KESTANELİK, KIZILCAALİ, MURATBEY MERKEZ (MERKEZ VE MEZRA), NAKKAŞ, OKLALI, ORMANLI, OVAYENİCE, ÖRCÜNLÜ, ÖRENCİK, SUBAŞI, YALIKÖY, YAYLACIK, YAZLIK',\n",
        "    'SİLİVRİ': 'AKÖREN, ALİPAŞA, BEKİRLİ, BEYCİLER, BÜYÜKÇAVUŞLU, BÜYÜKKILIÇLI, BÜYÜKSİNEKLİ, ÇAYIRDERE, ÇELTİK, DANAMANDIRA, FENER, GAZİTEPE, KADIKÖY, KURFALLI, KÜÇÜKKILIÇLI, KÜÇÜKSİNEKLİ, SAYALAR, SEYMEN, YOLÇATI',\n",
        "    'BEYKOZ': 'AKBABA, ALİBAHADIR, ANADOLUFENERİ, BOZHANE, CUMHURİYET, DERESEKİ, ELMALI, GÖLLÜ, GÖRELE, İSHAKLI, KAYNARCA, KILIÇLI, MAHMUTŞEVKETPAŞA , ÖĞÜMCE, ÖRNEKKÖY, PAŞAMANDIRA, POLONEZKÖY,  POYRAZKÖY, RİVA, ZERZEVATÇI',\n",
        "    'ŞİLE': 'ŞİLE: AĞAÇDERE, AHMETLİ, AKÇAKESE, ALACALI, AVCIKORU, BIÇKIDERE, BOZGOCA, BUCAKLI, ÇATAKLI, ÇAYIRBAŞI, ÇELEBİ, ÇENGİLLİ, DARLIK, DEĞİRMENÇAYIRI, DOĞANCALI, ERENLER, ESENCELİ, GEREDELİ, GÖÇE, GÖKMAŞLI, GÖKSU, HACILI, HASANLI, İMRENDERE, İMRENLİ, İSAKÖY, KABAKOZ, KADIKÖY, KALEM, KARABEYLİ, KARACAKÖY, KARAKİRAZ, KARAMANDERE, KERVANSARAY, KIZILCA, KORUCU, KÖMÜRLÜK, KURFALLI, KURNA, MEŞRUTİYET, ORUÇOĞLU, OSMANKÖY, OVACIK, SAHİLKÖY, SATMAZLI, SOFULAR, SOĞULLU, SORTULLU, ŞUAYİPLİ, TEKE, ULUPELİT, ÜVEZLİ, YAKA, YAYLALI,YAZIMANAYIR, YENİKÖY, YEŞİLVADİ'\n",
        "  }"
      ],
      "metadata": {
        "id": "Rmi7wueDyyKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rural_new"
      ],
      "metadata": {
        "id": "HKuTGOcvDg15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_rural(row):\n",
        "  keyword= {\n",
        "    'SARIYER': 'BAHÇEKÖY, DEMİRCİKÖY, GARİPÇE, GÜMÜŞDERE, KISIRKAYA, KUMKÖY, RUMELİFENERİ, USKUMRU, ZEKERİYE',\n",
        "    'ARNAVUTKÖY': 'BAKLALI, BALABAN, BOYALIK, ÇİLİNGİR, DURSUNKÖY, HACIMAŞLI, KARABURUN, SAZLIBOSNA, TAYAKADIN, YASSIÖREN, YENİKÖY, YEŞİLBAYIR',\n",
        "    'ÇATALCA': 'ATATÜRK, AKALAN, AYDINLAR, BAHŞAYİŞ, BAŞAK, BELGRAT, CELEPKÖY, ÇAKIL, ÇANAKÇA, ÇİFTLİKKÖY, DAĞYENİCE, ELBASAN, FATİH, GÖKÇEALİ, GÜMÜŞPINAR, HALLAÇLI, HİSARBEYLİ, İHSANİYE (MERKEZ VE PINARCA MEVKİİ), İNCEĞİZ, İZZETTİN, KABAKÇA, KALFA, KARACAKÖY MERKEZ, KARAMANDERE, KESTANELİK, KIZILCAALİ, MURATBEY MERKEZ (MERKEZ VE MEZRA), NAKKAŞ, OKLALI, ORMANLI, OVAYENİCE, ÖRCÜNLÜ, ÖRENCİK, SUBAŞI, YALIKÖY, YAYLACIK, YAZLIK',\n",
        "    'SİLİVRİ': 'AKÖREN, ALİPAŞA, BEKİRLİ, BEYCİLER, BÜYÜKÇAVUŞLU, BÜYÜKKILIÇLI, BÜYÜKSİNEKLİ, ÇAYIRDERE, ÇELTİK, DANAMANDIRA, FENER, GAZİTEPE, KADIKÖY, KURFALLI, KÜÇÜKKILIÇLI, KÜÇÜKSİNEKLİ, SAYALAR, SEYMEN, YOLÇATI',\n",
        "    'BEYKOZ': 'AKBABA, ALİBAHADIR, ANADOLUFENERİ, BOZHANE, CUMHURİYET, DERESEKİ, ELMALI, GÖLLÜ, GÖRELE, İSHAKLI, KAYNARCA, KILIÇLI, MAHMUTŞEVKETPAŞA , ÖĞÜMCE, ÖRNEKKÖY, PAŞAMANDIRA, POLONEZKÖY,  POYRAZKÖY, RİVA, ZERZEVATÇI',\n",
        "    'ŞİLE': 'ŞİLE: AĞAÇDERE, AHMETLİ, AKÇAKESE, ALACALI, AVCIKORU, BIÇKIDERE, BOZGOCA, BUCAKLI, ÇATAKLI, ÇAYIRBAŞI, ÇELEBİ, ÇENGİLLİ, DARLIK, DEĞİRMENÇAYIRI, DOĞANCALI, ERENLER, ESENCELİ, GEREDELİ, GÖÇE, GÖKMAŞLI, GÖKSU, HACILI, HASANLI, İMRENDERE, İMRENLİ, İSAKÖY, KABAKOZ, KADIKÖY, KALEM, KARABEYLİ, KARACAKÖY, KARAKİRAZ, KARAMANDERE, KERVANSARAY, KIZILCA, KORUCU, KÖMÜRLÜK, KURFALLI, KURNA, MEŞRUTİYET, ORUÇOĞLU, OSMANKÖY, OVACIK, SAHİLKÖY, SATMAZLI, SOFULAR, SOĞULLU, SORTULLU, ŞUAYİPLİ, TEKE, ULUPELİT, ÜVEZLİ, YAKA, YAYLALI,YAZIMANAYIR, YENİKÖY, YEŞİLVADİ'\n",
        "  }\n",
        "  if row['İLÇE_ARGE'] in keyword.keys():\n",
        "    if row['MAHALLE_ARGE'] in keyword[row['İLÇE_ARGE']]:\n",
        "      return 'KIRSAL'\n",
        "    else:\n",
        "      return 'KENTSEL'\n",
        "  else:\n",
        "    return 'KENTSEL'"
      ],
      "metadata": {
        "id": "cfCXM9z39Y_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['URBAN-RURAL'] = df.apply(find_rural, axis=1)"
      ],
      "metadata": {
        "id": "Q0A193np5ETc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['VAKA VERILIS TARIH SAAT']= df['VAKA VERILIS\\nTARIHI'] + ' ' + df['VAKA VERILIS\\nSAATI']\n",
        "df['VAKA CIKIS TARIH SAAT'] = df['VAKAYA CIKIS TARIHI'] + ' '+ df['VAKAYA CIKIS SAATI']\n",
        "df['OLAY YER VARIS TARIH SAAT']= df['OLAY YERI VARIS TARIHI'] + ' ' + df['OLAY YERI VARIS SAATI']"
      ],
      "metadata": {
        "id": "nuiwYshU6v7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_datetime(row):\n",
        "  try:\n",
        "    return pd.to_datetime(row, format= '%d-%m-%Y %H:%M:%S')\n",
        "  except:\n",
        "    try:\n",
        "      return pd.to_datetime(row, format= '%Y-%m-%d %H:%M:%S')\n",
        "    except:\n",
        "      return '-'\n",
        "df['VAKA VERILIS TARIH SAAT'] = df['VAKA VERILIS TARIH SAAT'].apply(to_datetime)\n",
        "df['VAKA CIKIS TARIH SAAT'] = df['VAKA CIKIS TARIH SAAT'].apply(to_datetime)\n",
        "df['OLAY YER VARIS TARIH SAAT'] = df['OLAY YER VARIS TARIH SAAT'].apply(to_datetime)"
      ],
      "metadata": {
        "id": "VJsE5Dzl9Qdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "1Hd00OMNisUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Saat Aralığı']= df['VAKA VERILIS TARIH SAAT'].dt.strftime('%H')"
      ],
      "metadata": {
        "id": "x-e2e3xNkBi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df= df.copy()"
      ],
      "metadata": {
        "id": "E3mbG7s8kBlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df= temp_df[temp_df['İLÇE_ARGE']!='BELİRTİLMEMİŞ']"
      ],
      "metadata": {
        "id": "Ou6EwnrI9npM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['Gün'] = temp_df['VAKA VERILIS TARIH SAAT'].dt.day_name(locale= 'tr_TR')"
      ],
      "metadata": {
        "id": "Eg4zxtu_GEet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df"
      ],
      "metadata": {
        "id": "nUyUKG34IA0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89_n4WbCpER5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['Gün']= temp_df['Gün'].str.replace('ý','I').str.replace('þ','Ş')"
      ],
      "metadata": {
        "id": "bdojONj9IKqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['Gün']= temp_df['Gün'].str.replace('i','İ').str.replace('ı','I').str.replace('ö','Ö').str.replace('ü','Ü').str.replace('ş','Ş').str.replace('ç','Ç').str.replace('ğ','Ğ').str.upper()"
      ],
      "metadata": {
        "id": "r23c8f0MGLvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['ulasim_suresi']= (temp_df['OLAY YER VARIS TARIH SAAT'] - temp_df['VAKA CIKIS TARIH SAAT']).dt.seconds"
      ],
      "metadata": {
        "id": "D7zjMG9HaDdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df[temp_df['URBAN-RURAL']=='KENTSEL']['ulasim_suresi'].mean()"
      ],
      "metadata": {
        "id": "kB90UtXSaDf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df[temp_df['URBAN-RURAL']=='KIRSAL']['ulasim_suresi'].mean()"
      ],
      "metadata": {
        "id": "tdB6xBagaDic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ngKR4leduth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8voufEDIduv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_of_week= ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA', 'CUMARTESİ', 'PAZAR']\n",
        "temp_df['Gün'] = pd.Categorical(temp_df['Gün'], categories=day_of_week, ordered=True)"
      ],
      "metadata": {
        "id": "OQzXr838HYO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#temp_df['Gün'] = pd.Categorical(temp_df['Gün'], categories=day_of_week, ordered=True)"
      ],
      "metadata": {
        "id": "R9Y5KNZ1k9QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['Gün'].unique()"
      ],
      "metadata": {
        "id": "1yPiDmcQHeVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['Saat Aralığı'].unique()"
      ],
      "metadata": {
        "id": "uIXe6xOmGO3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['ulasim_suresi']= temp_df['ulasim_suresi'].astype('float32')"
      ],
      "metadata": {
        "id": "fbndzAyxcvZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#temp_df['gecikme']= temp_df.apply(lambda x: 1 if (((x['URBAN-RURAL'] == 'KENTSEL') and (x['ulasim_suresi'] > 600)) or ((x['URBAN-RURAL']=='KIRSAL') and x['ulasim_suresi'] > 1800)) else 0, axis=1)"
      ],
      "metadata": {
        "id": "WLGiDMtTKyTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#temp_df.groupby(['İLÇE_ARGE','MAHALLE_ARGE','Saat Aralığı']).agg({'Value':'sum'}).drop(index='BELİRTİLMEMİŞ').reset_index().to_excel('saatlik_vaka_sayisi.xlsx')"
      ],
      "metadata": {
        "id": "6zdHwjnWk9LH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['Ay']= temp_df['VAKA VERILIS TARIH SAAT'].dt.month"
      ],
      "metadata": {
        "id": "671f3gtXk9Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['Ay'].unique()"
      ],
      "metadata": {
        "id": "Di-5i-zDKHy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df[(temp_df['ulasim_suresi']>1800) & (temp_df['URBAN-RURAL']=='KIRSAL')]"
      ],
      "metadata": {
        "id": "qeJtF90FFYtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['Value']= 1"
      ],
      "metadata": {
        "id": "WOzP1I8sSeBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['Value']= temp_df['Value'].astype(int)"
      ],
      "metadata": {
        "id": "YHiLUeplFgXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_pivot= temp_df.pivot_table(index=['İLÇE_ARGE','MAHALLE_ARGE','Saat Aralığı'], columns=['Ay','Gün'], values='Value', aggfunc='sum')"
      ],
      "metadata": {
        "id": "InUaRquwk9YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_pivot.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "Si1YOyVMFNxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.rename(columns={'Saat Aralığı':'hour', 'ulasim_suresi':'reach_time'}, inplace=True)"
      ],
      "metadata": {
        "id": "7oLLYyry44gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df[(temp_df['reach_time']>=3600)].to_excel(unfinished_works_path+'hourly_district_reach_times/unnormal_late.xlsx')"
      ],
      "metadata": {
        "id": "g2Gv8y4RvIp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df[temp_df['OLAY YER VARIS TARIH SAAT'] < temp_df[\"VAKA CIKIS TARIH SAAT\"]].to_excel('unnormal_times.xlsx')"
      ],
      "metadata": {
        "id": "HlznfiZpvIu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df= temp_df[((temp_df['reach_time']<=3600) & (temp_df['OLAY YER VARIS TARIH SAAT'] > temp_df[\"VAKA CIKIS TARIH SAAT\"]))]"
      ],
      "metadata": {
        "id": "A7XOnT6mvIxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.head()"
      ],
      "metadata": {
        "id": "DKlDKGwBvIzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['hour']= temp_df['hour'].astype(int)"
      ],
      "metadata": {
        "id": "5V7jDItneXSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_df= temp_df[(temp_df['hour'] >= 10) & (temp_df['hour']<=22)]"
      ],
      "metadata": {
        "id": "DtfdzVf2vI2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_df[hour_df['hour']==22]"
      ],
      "metadata": {
        "id": "nUxImFiNvI5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(list(temp_df['EKIP NO'].unique()))"
      ],
      "metadata": {
        "id": "DkAePj-avI7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df"
      ],
      "metadata": {
        "id": "o-D65ZSv2Jba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EnorXlwm4AOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backup_df= temp_df.copy()"
      ],
      "metadata": {
        "id": "3ZuhO2IV3TWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df= backup_df.copy()"
      ],
      "metadata": {
        "id": "ETGAtSLs4QmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "district_locations= pd.read_excel('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/data/locations/district_locations.xlsx')"
      ],
      "metadata": {
        "id": "EyKGK-kA4BLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "district_locations['Latitude']= district_locations['Latitude'].astype('float32')\n",
        "district_locations['Longitude']= district_locations['Longitude'].astype('float32')"
      ],
      "metadata": {
        "id": "5E0az1_oeqgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "district_locations"
      ],
      "metadata": {
        "id": "8-J2c4y_ew1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df= pd.merge(temp_df, district_locations, on=['İLÇE_ARGE', 'MAHALLE_ARGE'], how='inner')"
      ],
      "metadata": {
        "id": "ALr41aWP4UKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df"
      ],
      "metadata": {
        "id": "vA6kT-mbBCFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['MAHALLE_ARGE']= temp_df['MAHALLE_ARGE'].str.strip()\n",
        "temp_df['İLÇE_ARGE']= temp_df['İLÇE_ARGE'].str.strip()\n",
        "temp_df['Ay']= temp_df['Ay'].astype(int)\n",
        "temp_df['Gün']= temp_df['Gün'].str.strip()\n",
        "temp_df['hour']= temp_df['hour'].astype(int)"
      ],
      "metadata": {
        "id": "BQVrUvLjYhBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#temp_df.head(50).to_excel('test.xlsx')"
      ],
      "metadata": {
        "id": "vpfYmu2ZdxhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "sdgZFRs4jlF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DP2_Fj3O0jWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['VAKANIN ENLEMI']= temp_df['VAKANIN ENLEMI'].astype('float32')\n",
        "temp_df['VAKANIN BOYLAMI']= temp_df['VAKANIN BOYLAMI'].astype('float32')"
      ],
      "metadata": {
        "id": "ZOLPqP_30Vsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df[['Ay','Gün','hour','VAKANIN ENLEMI','VAKANIN BOYLAMI','Latitude','Longitude']].info()"
      ],
      "metadata": {
        "id": "T85t1vduzdEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df[temp_df['VAKANIN ENLEMI']=='-']"
      ],
      "metadata": {
        "id": "rDJTi7vg15Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backup_df= temp_df.copy()"
      ],
      "metadata": {
        "id": "tH30oPKB2NYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['gecikme_miktari']= temp_df.apply(lambda x: ((x['reach_time'] - 600) if ((x['gecikme']==1) and x['URBAN-RURAL']=='KENTSEL') else ((x['reach_time'] - 1800) if ((x['gecikme']==1) and x['URBAN-RURAL']=='KIRSAL') else 0)), axis=1)"
      ],
      "metadata": {
        "id": "Rqlmeh7B7uCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df_grouped= temp_df.groupby(['İLÇE_ARGE','MAHALLE_ARGE','Ay','Gün','hour']).agg({'Value':'sum', 'reach_time':'mean', 'Longitude':'max', 'Latitude':'max'}).reset_index().sort_values(by='Value', ascending=False).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "ksJptlZZ9OiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df_grouped['coefficiency']= temp_df_grouped['reach_time'] * temp_df_grouped['Value']"
      ],
      "metadata": {
        "id": "qvLf0GagDRtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df[temp_df['reach_time']==temp_df['reach_time'].max()]"
      ],
      "metadata": {
        "id": "HlKD72CeEZ7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iI0AZSK8E09p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gd9JWxssE0_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H-hd2MApE1CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J0vOVoPzE1FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TlJ_ki38E1G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_of_week = ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA', 'CUMARTESİ', 'PAZAR']\n",
        "temp_df_grouped['Gün'] = pd.Categorical(temp_df_grouped['Gün'], categories=day_of_week, ordered=True)"
      ],
      "metadata": {
        "id": "Xsrnc-y9E1I8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df_grouped"
      ],
      "metadata": {
        "id": "0Ra6nJVuNMBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['hour']= temp_df['hour'].astype(int)\n",
        "temp_df.sort_values(by='hour', inplace=True)"
      ],
      "metadata": {
        "id": "jbUBrPzoS7xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour= [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
        "temp_df['hour'] = pd.Categorical(temp_df['hour'], categories=hour, ordered=True)"
      ],
      "metadata": {
        "id": "53ADjbCiTy0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0dYFzewia-XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_df= temp_df[['KKM PROTOKOL','EKIP NO','Ay','Gün','hour','VAKANIN ENLEMI','VAKANIN BOYLAMI','Latitude','Longitude','gecikme_miktari']]"
      ],
      "metadata": {
        "id": "vHGHLPNk2B6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "gAo-3fu12mNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_df"
      ],
      "metadata": {
        "id": "oPX2Jmzp5f_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_df.to_csv('hour_df.csv')"
      ],
      "metadata": {
        "id": "YdhXn-TB0Pks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_df[(hour_df['Gün']=='CUMARTESİ')]"
      ],
      "metadata": {
        "id": "7EMbcrU--DsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_map(hour_df[hour_df['Ay']==1])"
      ],
      "metadata": {
        "id": "-znIHQ7wfBjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oN4CPIbAfBlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AajL_Zd77N22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g7YPWCv17N5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vygvxoyE7N7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D3nm9u6P7N_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GrPYe3cqzrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vBFXZY3OqzuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P86r6vhWqzwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJ_kWvT7qzyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "07uBovk3qz02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADPHKm_1qz3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-9mTVHKqz5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lThSkWpaqz8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime # Import the datetime module\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler # Import the MinMaxScaler\n"
      ],
      "metadata": {
        "id": "r_D6nNxLqz-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.concat([df3['54230'],df4['48247'], df5['49926'],df6['NİSAN - 50.014'], df7['52340'], df8['52852-DEFTER'], df9['55923 defter avrupa']])"
      ],
      "metadata": {
        "id": "jDnqE7a2uRUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2td7aCJw8hJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Generate graph by Reach Time\n",
        "\n",
        "def to_datetime(row):\n",
        "  try:\n",
        "    return pd.to_datetime(row, format= '%d-%m-%Y %H:%M:%S')\n",
        "  except:\n",
        "    try:\n",
        "      return pd.to_datetime(row, format= '%Y-%m-%d %H:%M:%S')\n",
        "    except:\n",
        "      return '-'\n",
        "\n",
        "def location_set(row):\n",
        "\n",
        "  if row['VAKANIN ENLEMI']=='-':\n",
        "    row['VAKANIN ENLEMI']= row['Latitude']\n",
        "    row['VAKANIN BOYLAMI']= row['Longitude']\n",
        "  return row\n",
        "\n",
        "\n",
        "def recalculate_reach(row):\n",
        "  if row['URBAN-RURAL']=='KIRSAL':\n",
        "    row['reach_time']= row['reach_time'] / 3\n",
        "    return row['reach_time']\n",
        "  else:\n",
        "    return row['reach_time']\n",
        "\n",
        "def load_district():\n",
        "  %run find_district.py\n",
        "\n",
        "def load_rural():\n",
        "  %run find_rural.py\n",
        "\n",
        "def load_district_locations():\n",
        "  district_locations= pd.read_excel('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/data/locations/district_locations.xlsx')\n",
        "  district_locations['Latitude']= district_locations['Latitude'].astype('float32')\n",
        "  district_locations['Longitude']= district_locations['Longitude'].astype('float32')\n",
        "  return district_locations\n",
        "\n",
        "def process_data(df):\n",
        "\n",
        "  load_district()\n",
        "  load_rural()\n",
        "\n",
        "  df = find_district(df)  # Apply district processing\n",
        "\n",
        "  df['URBAN-RURAL'] = df.apply(find_rural, axis=1)\n",
        "\n",
        "  df['VAKA VERILIS TARIH SAAT']= df['VAKA VERILIS\\nTARIHI'] + ' ' + df['VAKA VERILIS\\nSAATI']\n",
        "  df['VAKA CIKIS TARIH SAAT'] = df['VAKAYA CIKIS TARIHI'] + ' '+ df['VAKAYA CIKIS SAATI']\n",
        "  df['OLAY YER VARIS TARIH SAAT']= df['OLAY YERI VARIS TARIHI'] + ' ' + df['OLAY YERI VARIS SAATI']\n",
        "\n",
        "  df['VAKA VERILIS TARIH SAAT'] = df['VAKA VERILIS TARIH SAAT'].apply(to_datetime)\n",
        "\n",
        "  df['VAKA CIKIS TARIH SAAT'] = df['VAKA CIKIS TARIH SAAT'].apply(to_datetime)\n",
        "  df['OLAY YER VARIS TARIH SAAT']= df['OLAY YER VARIS TARIH SAAT'].apply(to_datetime)\n",
        "\n",
        "\n",
        "  df['hour']= df['VAKA VERILIS TARIH SAAT'].dt.strftime('%H')\n",
        "\n",
        "  df= df[df['İLÇE_ARGE']!='BELİRTİLMEMİŞ']\n",
        "\n",
        "  df['Gün'] = df['VAKA VERILIS TARIH SAAT'].dt.day_name(locale= 'tr_TR')\n",
        "  df['Ay']= df['VAKA VERILIS TARIH SAAT'].dt.month\n",
        "  df['Yıl']= df['VAKA VERILIS TARIH SAAT'].dt.year\n",
        "  df['Gün']= df['Gün'].str.replace('ý','I').str.replace('þ','Ş')\n",
        "\n",
        "  df['Gün']= df['Gün'].str.replace('i','İ').str.replace('ı','I').str.replace('ö','Ö').str.replace('ü','Ü').str.replace('ş','Ş').str.replace('ç','Ç').str.replace('ğ','Ğ').str.upper()\n",
        "\n",
        "\n",
        "  df['ulasim_suresi']= (df['OLAY YER VARIS TARIH SAAT'] - df['VAKA CIKIS TARIH SAAT']).dt.seconds\n",
        "  df['ulasim_suresi']= df['ulasim_suresi'].astype('float32')\n",
        "\n",
        "\n",
        "\n",
        "  day_of_week= ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA', 'CUMARTESİ', 'PAZAR']\n",
        "  df['Gün'] = pd.Categorical(df['Gün'], categories=day_of_week, ordered=True)\n",
        "\n",
        "  df['Value']= 1\n",
        "\n",
        "  df['Value']= df['Value'].astype(int)\n",
        "\n",
        "  df.rename(columns={'ulasim_suresi':'reach_time'}, inplace=True)\n",
        "  df= df[((df['reach_time']<=3600) & (df['OLAY YER VARIS TARIH SAAT'] > df[\"VAKA CIKIS TARIH SAAT\"]))]\n",
        "  df['reach_time']= df['reach_time'].astype('float32')\n",
        "\n",
        "  df['reach_time']= df.apply(recalculate_reach, axis=1) # Add axis=1 to apply the function to each row\n",
        "\n",
        "  df['hour']= df['hour'].astype(int)\n",
        "\n",
        "  df= df[(df['hour'] >= 10) & (df['hour']<22)]\n",
        "\n",
        "\n",
        "  district_locations= load_district_locations()\n",
        "\n",
        "  df= pd.merge(df, district_locations, on=['İLÇE_ARGE', 'MAHALLE_ARGE'], how='inner')\n",
        "\n",
        "  df['MAHALLE_ARGE']= df['MAHALLE_ARGE'].str.strip()\n",
        "  df['İLÇE_ARGE']= df['İLÇE_ARGE'].str.strip()\n",
        "  df['Ay']= df['Ay'].astype(int)\n",
        "  df['Gün']= df['Gün'].str.strip()\n",
        "  df['hour']= df['hour'].astype(int)\n",
        "\n",
        "  df = df.apply(location_set, axis=1)\n",
        "  df= df[df['VAKANIN ENLEMI'] != '-']\n",
        "  df= df[df['VAKANIN BOYLAMI'] != '-']\n",
        "  df['VAKANIN ENLEMI']= df['VAKANIN ENLEMI'].astype('float32')\n",
        "  df['VAKANIN BOYLAMI']= df['VAKANIN BOYLAMI'].astype('float32')\n",
        "\n",
        "  # Iterate over each group in the DataFrame, grouped by 'Ay' and 'Gün'\n",
        "  for (month, day), group in df.groupby(['Ay', 'Gün']):\n",
        "    # Apply logarithmic transformation to the 'reach_time' column for each group\n",
        "    log_scaled_data = np.log1p(group['reach_time'])\n",
        "\n",
        "    # Assign the scaled values back to the original DataFrame\n",
        "    df.loc[group.index, 'reach_time_scaled'] = log_scaled_data\n",
        "\n",
        "\n",
        "  # Initialize MinMaxScaler with a feature range (e.g., 1 to 100)\n",
        "  scaler = MinMaxScaler(feature_range=(1, 100))\n",
        "\n",
        "  # Iterate over each group in the DataFrame, grouped by 'Ay' and 'Gün'\n",
        "  for (month, day), group in df.groupby(['Ay', 'Gün']):\n",
        "      # Extract the log-scaled 'reach_time_scaled' column\n",
        "      log_scaled_data = group['reach_time_scaled'].values.reshape(-1, 1)\n",
        "\n",
        "      # Apply MinMax scaling to the log-scaled data\n",
        "      minmax_scaled_data = scaler.fit_transform(log_scaled_data)\n",
        "\n",
        "      # Assign the MinMax scaled values back to the original DataFrame\n",
        "      df.loc[group.index, 'reach_time_scaled'] = minmax_scaled_data.flatten()\n",
        "\n",
        "\n",
        "  # Fit and transform the reach_time column within each group\n",
        "  df= df[['Yıl','Ay','Gün','hour','reach_time','reach_time_scaled','VAKANIN ENLEMI','VAKANIN BOYLAMI','Latitude','Longitude']]\n",
        "\n",
        "  df.drop_duplicates(inplace=True)\n",
        "\n",
        "  return df\n",
        "df= process_data(df)"
      ],
      "metadata": {
        "id": "5gg86Ioc6Njf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(drop=True).to_csv('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/finished_works/projections/daily_hourly_case_intensity/europe_daily_hourly_case_intensity.csv', index=False)"
      ],
      "metadata": {
        "id": "ZXgNlO6q6R7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa= df.copy()"
      ],
      "metadata": {
        "id": "KXq1AV-QT9Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avrupa.drop(columns=['Longitude', 'Latitude'], inplace=True)"
      ],
      "metadata": {
        "id": "0BEl8ssU8hT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_excel('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/data/case_reports/europe/2024/monthly/1-OCAK 2024 AVR ASOS TANIDÖNÜŞTÜRÜLMÜŞ DEFTER.xlsx', usecols=['Vakanın Enlemi', 'Vakanın Boylamı','Vaka Veriliş\\nTarihi','Vaka Veriliş\\nSaati','Kensel/Kırsal','Olay Yeri Varış Tarihi','Olay Yeri Varış Saati' ])"
      ],
      "metadata": {
        "id": "18DLHraE2sSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_CiPr0qv2-Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-G-KwttJUKPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3lCtLUC6UKSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m0Mlu3xxUKUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkg_FnksUKWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bw99ZZ9XUKYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Generate graph by Reach Time ANADOLU ICIN\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime # Import the datetime module\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler # Import the MinMaxScaler\n",
        "\n",
        "def load_data():\n",
        "  eu_path= str(input('Lütfen Avrupa Vaka Raporunu Yükleyiniz: '))\n",
        "  asia_path= str(input('Lütfen Asya Vaka Raporunu Yükleyiniz: '))\n",
        "\n",
        "  try:\n",
        "    df_eu= pd.read_excel(eu_path, usecols=['Vakanın Enlemi', 'Vakanın Boylamı','Vaka Veriliş\\nTarihi','Vaka Veriliş\\nSaati','Vakaya Çıkış Tarihi','Vakaya Çıkış Saati','Olay Yeri Varış Tarihi','Olay Yeri Varış Saati','Kensel/Kırsal'])\n",
        "    df_eu['BOLGE']= 'Avrupa'\n",
        "    print('Avrupa Dosyası Yüklendi.')\n",
        "  except:\n",
        "    print('Avrupa Dosyası Yüklenmedi..')\n",
        "    df_eu= pd.DataFrame()\n",
        "\n",
        "  try:\n",
        "    df_asia= pd.read_excel(asia_path, usecols=['Vakanın Enlemi', 'Vakanın Boylamı','Vaka Veriliş\\nTarihi','Vaka Veriliş\\nSaati','Vakaya Çıkış Tarihi','Vakaya Çıkış Saati','Olay Yeri Varış Tarihi','Olay Yeri Varış Saati','Kensel/Kırsal'])\n",
        "    df_asia['BOLGE']= 'Asya'\n",
        "    print('Asya Dosyası Yüklendi.')\n",
        "  except:\n",
        "    print('Asya Dosyası Yüklenmedi..')\n",
        "    df_asia= pd.DataFrame()\n",
        "\n",
        "  return pd.concat([df_eu, df_asia])\n",
        "\n",
        "df= load_data()\n",
        "\n",
        "def to_datetime(row):\n",
        "  try:\n",
        "    return pd.to_datetime(row, format= '%d-%m-%Y %H:%M:%S')\n",
        "  except:\n",
        "    try:\n",
        "      return pd.to_datetime(row, format= '%Y-%m-%d %H:%M:%S')\n",
        "    except:\n",
        "      return '-'\n",
        "\n",
        "def recalculate_reach(row):\n",
        "  if row['KENSEL/KIRSAL']=='KIRSAL':\n",
        "    row['reach_time']= row['reach_time'] / 3\n",
        "    return row['reach_time']\n",
        "  else:\n",
        "    return row['reach_time']\n",
        "\n",
        "def to_datetime(row):\n",
        "  try:\n",
        "    return pd.to_datetime(row, format= '%d-%m-%Y %H:%M:%S')\n",
        "  except:\n",
        "    try:\n",
        "      return pd.to_datetime(row, format= '%Y-%m-%d %H:%M:%S')\n",
        "    except:\n",
        "      return '-'\n",
        "\n",
        "def recalculate_reach(row):\n",
        "  if row['KENSEL/KIRSAL']=='KIRSAL':\n",
        "    row['reach_time']= row['reach_time'] / 3\n",
        "    return row['reach_time']\n",
        "  else:\n",
        "    return row['reach_time']\n",
        "\n",
        "def process_data(df):\n",
        "    print('Kolonlar dönüştürülüyor')\n",
        "    df.columns = [col.strip().upper() for col in df.columns]\n",
        "\n",
        "    columns_list = []\n",
        "    for i in df.columns:\n",
        "        i = i.replace('-', ' ').replace('Ç', 'C').replace('Ğ', 'G').replace('İ', 'I').replace('Ö', 'O').replace('Ş', 'S').replace('Ü', 'U').strip()\n",
        "        columns_list.append(i)\n",
        "    df.columns = columns_list\n",
        "    print('Kolonlar dönüştürüldü.')\n",
        "\n",
        "    df['VAKA VERILIS TARIH SAAT']= df['VAKA VERILIS\\nTARIHI'] + ' ' + df['VAKA VERILIS\\nSAATI']\n",
        "    df['VAKA CIKIS TARIH SAAT'] = df['VAKAYA CIKIS TARIHI'] + ' '+ df['VAKAYA CIKIS SAATI']\n",
        "    df['OLAY YER VARIS TARIH SAAT']= df['OLAY YERI VARIS TARIHI'] + ' ' + df['OLAY YERI VARIS SAATI']\n",
        "\n",
        "    df['VAKA VERILIS TARIH SAAT'] = df['VAKA VERILIS TARIH SAAT'].apply(to_datetime)\n",
        "    df['VAKA CIKIS TARIH SAAT'] = df['VAKA CIKIS TARIH SAAT'].apply(to_datetime)\n",
        "    df['OLAY YER VARIS TARIH SAAT']= df['OLAY YER VARIS TARIH SAAT'].apply(to_datetime)\n",
        "\n",
        "    df['hour']= df['VAKA VERILIS TARIH SAAT'].dt.strftime('%H')\n",
        "\n",
        "    df['Gün'] = df['VAKA VERILIS TARIH SAAT'].dt.day_name(locale= 'tr_TR')\n",
        "    df['Gün']= df['Gün'].str.replace('ý','I').str.replace('þ','Ş')\n",
        "    df['Ay']= df['VAKA VERILIS TARIH SAAT'].dt.month\n",
        "    df['Yıl']= df['VAKA VERILIS TARIH SAAT'].dt.year\n",
        "\n",
        "    df['Gün']= df['Gün'].str.replace('i','İ').str.replace('ı','I').str.replace('ö','Ö').str.replace('ü','Ü').str.replace('ş','Ş').str.replace('ç','Ç').str.replace('ğ','Ğ').str.upper()\n",
        "\n",
        "    df['ulasim_suresi']= (df['OLAY YER VARIS TARIH SAAT'] - df['VAKA CIKIS TARIH SAAT']).dt.seconds\n",
        "    df['ulasim_suresi']= df['ulasim_suresi'].astype('float32')\n",
        "\n",
        "    day_of_week= ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA', 'CUMARTESİ', 'PAZAR']\n",
        "    df['Gün'] = pd.Categorical(df['Gün'], categories=day_of_week, ordered=True)\n",
        "\n",
        "    df['Value']= 1\n",
        "    df['Value']= df['Value'].astype(int)\n",
        "    df.rename(columns={'ulasim_suresi':'reach_time'}, inplace=True)\n",
        "\n",
        "    df= df[((df['reach_time']<=3600) & (df['OLAY YER VARIS TARIH SAAT'] > df[\"VAKA CIKIS TARIH SAAT\"]))]\n",
        "    df['reach_time']= df['reach_time'].astype('float32')\n",
        "    df['reach_time']= df.apply(recalculate_reach, axis=1)\n",
        "\n",
        "    df['hour']= df['hour'].astype(int)\n",
        "    df= df[(df['hour'] >= 10) & (df['hour']<22)]\n",
        "\n",
        "    df['Ay']= df['Ay'].astype(int)\n",
        "    df['Gün']= df['Gün'].str.strip()\n",
        "    df['hour']= df['hour'].astype(int)\n",
        "\n",
        "    df= df[df['VAKANIN ENLEMI'] != '-']\n",
        "    df= df[df['VAKANIN BOYLAMI'] != '-']\n",
        "    df['VAKANIN ENLEMI']= df['VAKANIN ENLEMI'].astype('float32')\n",
        "    df['VAKANIN BOYLAMI']= df['VAKANIN BOYLAMI'].astype('float32')\n",
        "\n",
        "    # Initialize MinMaxScaler\n",
        "    scaler = MinMaxScaler(feature_range=(1, 100))\n",
        "\n",
        "    # Apply log transformation and scaling within each group\n",
        "    df['reach_time_log'] = df.groupby(['BOLGE', 'Ay', 'Gün'])['reach_time'].transform(lambda x: np.log1p(x))\n",
        "    df['reach_time_scaled'] = df.groupby(['BOLGE', 'Ay', 'Gün'])['reach_time_log'].transform(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)).flatten())\n",
        "\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    return df\n",
        "df_converted= process_data(df)\n",
        "\n",
        "df= process_data(df)\n",
        "\n",
        "# Function to visualize the map using Plotly and ensure it's saved in the current directory\n",
        "# Function to visualize the map and save it\n",
        "\n",
        "def visualize_map(df, day, most_common_month, year):\n",
        "\n",
        "  print('Görselleştirmeler Başlıyor..')\n",
        "\n",
        "  try:\n",
        "      radius = 20 if len(df) < 15000 else 10\n",
        "      lat_center = df['VAKANIN ENLEMI'].mean()\n",
        "      lon_center = df['VAKANIN BOYLAMI'].mean()\n",
        "\n",
        "      # Create density mapbox plot\n",
        "      fig = px.density_mapbox(df, lat='VAKANIN ENLEMI', lon='VAKANIN BOYLAMI', radius=radius,\n",
        "                              center=dict(lat=lat_center, lon=lon_center), zoom=10,\n",
        "                              mapbox_style=\"open-street-map\", opacity=0.7,\n",
        "                              color_continuous_scale=[\"blue\", \"yellow\", \"red\"],\n",
        "                              z='reach_time_scaled',\n",
        "                              animation_frame='hour'\n",
        "                              )\n",
        "\n",
        "      # Update the layout with custom titles\n",
        "      fig.update_layout(\n",
        "          title=f\"VAKA YOĞUNLUK HARİTASI {day}, {most_common_month}. AY, {year}\",  # Main title\n",
        "          title_x=0.5,  # Center the title\n",
        "          coloraxis_colorbar=dict(\n",
        "              title=\"PUAN\",  # Color bar title\n",
        "          ),\n",
        "          geo=dict(\n",
        "              showland=True,  # Show land\n",
        "              landcolor=\"lightgray\"\n",
        "          )\n",
        "      )\n",
        "\n",
        "      # Adding the legacy as a text annotation\n",
        "      fig.add_annotation(\n",
        "          text=\"AVRUPA112 */ Muhammed KAYA\",\n",
        "          showarrow=False,\n",
        "          xref=\"paper\", yref=\"paper\",\n",
        "          x=0.95, y=0.05,  # Adjust position as needed\n",
        "          font=dict(size=12, color=\"black\")  # Adjust font size and color as needed\n",
        "      )\n",
        "\n",
        "      # Ensure day and year are converted to strings\n",
        "      filename = f'{most_common_month}_{str(day)}_{str(year)}_mapbox_graph.html'\n",
        "\n",
        "      file_path = str(input('Kaydetme Konumunu Seçiniz: ')) #'C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/finished_works/projections/daily_hourly_case_intensity/'\n",
        "\n",
        "      month_path = f'{file_path}/{str(year)}_{most_common_month}/'\n",
        "\n",
        "      if not os.path.exists(month_path):\n",
        "          os.makedirs(month_path)\n",
        "\n",
        "      # Save the graph as an HTML file in the specified directory\n",
        "      fig.write_html(os.path.join(month_path, filename))\n",
        "\n",
        "      # Print confirmation that the file was created successfully\n",
        "      print(f\"Graph saved successfully as {filename}\")\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"Failed to generate graph for {day}: {e}\")\n",
        "\n",
        "\n",
        "# Example function to generate graphs for all days of the week\n",
        "def generate_graphs_for_all_days(df):\n",
        "\n",
        "    year = df['Yıl'].unique()[0]  # Get the year\n",
        "\n",
        "    days_of_week = [\"PAZARTESİ\", \"SALI\", \"ÇARŞAMBA\", \"PERŞEMBE\", \"CUMA\", \"CUMARTESİ\", \"PAZAR\"]\n",
        "    for month in df['Ay'].unique():\n",
        "        filtered_df = df[df['Ay'] == month]\n",
        "        most_common_month = month  # Get the most frequent month\n",
        "\n",
        "        if not filtered_df.empty:\n",
        "          for day in days_of_week:\n",
        "              selected_df = filtered_df[filtered_df['Gün'] == day]\n",
        "              if not selected_df.empty:\n",
        "                  visualize_map(selected_df, day, most_common_month, year)\n",
        "\n",
        "generate_graphs_for_all_days(df)"
      ],
      "metadata": {
        "id": "7F7wSqJ6fBnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sWjsrUrj8WoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hBduwXNp8Wq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WjlDGV7W8Ws6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BwCUpJha8WvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQyuIXqf8Wxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sCtHlb5N8Wzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Generate graph by Reach Time ANADOLU ICIN\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime # Import the datetime module\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler # Import the MinMaxScaler\n",
        "\n",
        "def load_data():\n",
        "  eu_path= str(input('Lütfen Avrupa Vaka Raporunu Yükleyiniz: '))\n",
        "  asia_path= str(input('Lütfen Asya Vaka Raporunu Yükleyiniz: '))\n",
        "\n",
        "  try:\n",
        "    df_eu= pd.read_excel(eu_path, usecols=['Vakanın Enlemi', 'Vakanın Boylamı','Vaka Veriliş\\nTarihi','Vaka Veriliş\\nSaati','Vakaya Çıkış Tarihi','Vakaya Çıkış Saati','Olay Yeri Varış Tarihi','Olay Yeri Varış Saati','Kensel/Kırsal'])\n",
        "    df_eu['BOLGE']= 'Avrupa'\n",
        "    print('Avrupa Dosyası Yüklendi.')\n",
        "  except:\n",
        "    print('Avrupa Dosyası Yüklenmedi..')\n",
        "    df_eu= pd.DataFrame()\n",
        "\n",
        "  try:\n",
        "    df_asia= pd.read_excel(asia_path, usecols=['Vakanın Enlemi', 'Vakanın Boylamı','Vaka Veriliş\\nTarihi','Vaka Veriliş\\nSaati','Vakaya Çıkış Tarihi','Vakaya Çıkış Saati','Olay Yeri Varış Tarihi','Olay Yeri Varış Saati','Kensel/Kırsal'])\n",
        "    df_asia['BOLGE']= 'Asya'\n",
        "    print('Asya Dosyası Yüklendi.')\n",
        "  except:\n",
        "    print('Asya Dosyası Yüklenmedi..')\n",
        "    df_asia= pd.DataFrame()\n",
        "\n",
        "  return pd.concat([df_eu, df_asia])\n",
        "\n",
        "df= load_data()\n",
        "\n",
        "def to_datetime(row):\n",
        "  try:\n",
        "    return pd.to_datetime(row, format= '%d-%m-%Y %H:%M:%S')\n",
        "  except:\n",
        "    try:\n",
        "      return pd.to_datetime(row, format= '%Y-%m-%d %H:%M:%S')\n",
        "    except:\n",
        "      return '-'\n",
        "\n",
        "def recalculate_reach(row):\n",
        "  if row['KENSEL/KIRSAL']=='KIRSAL':\n",
        "    row['reach_time']= row['reach_time'] / 3\n",
        "    return row['reach_time']\n",
        "  else:\n",
        "    return row['reach_time']\n",
        "\n",
        "def to_datetime(row):\n",
        "  try:\n",
        "    return pd.to_datetime(row, format= '%d-%m-%Y %H:%M:%S')\n",
        "  except:\n",
        "    try:\n",
        "      return pd.to_datetime(row, format= '%Y-%m-%d %H:%M:%S')\n",
        "    except:\n",
        "      return '-'\n",
        "\n",
        "def recalculate_reach(row):\n",
        "  if row['KENSEL/KIRSAL']=='KIRSAL':\n",
        "    row['reach_time']= row['reach_time'] / 3\n",
        "    return row['reach_time']\n",
        "  else:\n",
        "    return row['reach_time']\n",
        "\n",
        "def process_data(df):\n",
        "    print('Kolonlar dönüştürülüyor')\n",
        "    df.columns = [col.strip().upper() for col in df.columns]\n",
        "\n",
        "    columns_list = []\n",
        "    for i in df.columns:\n",
        "        i = i.replace('-', ' ').replace('Ç', 'C').replace('Ğ', 'G').replace('İ', 'I').replace('Ö', 'O').replace('Ş', 'S').replace('Ü', 'U').strip()\n",
        "        columns_list.append(i)\n",
        "    df.columns = columns_list\n",
        "    print('Kolonlar dönüştürüldü.')\n",
        "\n",
        "    df['VAKA VERILIS TARIH SAAT']= df['VAKA VERILIS\\nTARIHI'] + ' ' + df['VAKA VERILIS\\nSAATI']\n",
        "    df['VAKA CIKIS TARIH SAAT'] = df['VAKAYA CIKIS TARIHI'] + ' '+ df['VAKAYA CIKIS SAATI']\n",
        "    df['OLAY YER VARIS TARIH SAAT']= df['OLAY YERI VARIS TARIHI'] + ' ' + df['OLAY YERI VARIS SAATI']\n",
        "\n",
        "    df['VAKA VERILIS TARIH SAAT'] = df['VAKA VERILIS TARIH SAAT'].apply(to_datetime)\n",
        "    df['VAKA CIKIS TARIH SAAT'] = df['VAKA CIKIS TARIH SAAT'].apply(to_datetime)\n",
        "    df['OLAY YER VARIS TARIH SAAT']= df['OLAY YER VARIS TARIH SAAT'].apply(to_datetime)\n",
        "\n",
        "    df['hour']= df['VAKA VERILIS TARIH SAAT'].dt.strftime('%H')\n",
        "\n",
        "    df['Gün'] = df['VAKA VERILIS TARIH SAAT'].dt.day_name(locale= 'tr_TR')\n",
        "    df['Gün']= df['Gün'].str.replace('ý','I').str.replace('þ','Ş')\n",
        "    df['Ay']= df['VAKA VERILIS TARIH SAAT'].dt.month\n",
        "    df['Yıl']= df['VAKA VERILIS TARIH SAAT'].dt.year\n",
        "\n",
        "    df['Gün']= df['Gün'].str.replace('i','İ').str.replace('ı','I').str.replace('ö','Ö').str.replace('ü','Ü').str.replace('ş','Ş').str.replace('ç','Ç').str.replace('ğ','Ğ').str.upper()\n",
        "\n",
        "    df['ulasim_suresi']= (df['OLAY YER VARIS TARIH SAAT'] - df['VAKA CIKIS TARIH SAAT']).dt.seconds\n",
        "    df['ulasim_suresi']= df['ulasim_suresi'].astype('float32')\n",
        "\n",
        "    day_of_week= ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA', 'CUMARTESİ', 'PAZAR']\n",
        "    df['Gün'] = pd.Categorical(df['Gün'], categories=day_of_week, ordered=True)\n",
        "    df['week_day']= df['Gün'].apply(lambda x: 'HAFTA İÇİ' if x in ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA'] else 'HAFTA SONU')\n",
        "    df['Value']= 1\n",
        "    df['Value']= df['Value'].astype(int)\n",
        "    df.rename(columns={'ulasim_suresi':'reach_time'}, inplace=True)\n",
        "\n",
        "    df= df[((df['reach_time']<=3600) & (df['OLAY YER VARIS TARIH SAAT'] > df[\"VAKA CIKIS TARIH SAAT\"]))]\n",
        "    df['reach_time']= df['reach_time'].astype('float32')\n",
        "    df['reach_time']= df.apply(recalculate_reach, axis=1)\n",
        "\n",
        "    df['hour']= df['hour'].astype(int)\n",
        "    df= df[(df['hour'] >= 10) & (df['hour']<22)]\n",
        "\n",
        "    df['Ay']= df['Ay'].astype(int)\n",
        "    df['Gün']= df['Gün'].str.strip()\n",
        "    df['hour']= df['hour'].astype(int)\n",
        "\n",
        "    df= df[df['VAKANIN ENLEMI'] != '-']\n",
        "    df= df[df['VAKANIN BOYLAMI'] != '-']\n",
        "    df['VAKANIN ENLEMI']= df['VAKANIN ENLEMI'].astype('float32')\n",
        "    df['VAKANIN BOYLAMI']= df['VAKANIN BOYLAMI'].astype('float32')\n",
        "\n",
        "    # Initialize MinMaxScaler\n",
        "    scaler = MinMaxScaler(feature_range=(1, 100))\n",
        "\n",
        "    # Apply log transformation and scaling within each group\n",
        "    df['reach_time_log'] = df.groupby(['BOLGE', 'Ay', 'Gün'])['reach_time'].transform(lambda x: np.log1p(x))\n",
        "    df['reach_time_scaled'] = df.groupby(['BOLGE', 'Ay', 'Gün'])['reach_time_log'].transform(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)).flatten())\n",
        "\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    return df\n",
        "df_converted= process_data(df)\n",
        "\n",
        "df= process_data(df)\n",
        "\n",
        "# Function to visualize the map using Plotly and ensure it's saved in the current directory\n",
        "# Function to visualize the map and save it\n",
        "\n",
        "def visualize_map(df, day, most_common_month, year):\n",
        "\n",
        "  print('Görselleştirmeler Başlıyor..')\n",
        "\n",
        "  try:\n",
        "      radius = 20 if len(df) < 15000 else 10\n",
        "      lat_center = df['VAKANIN ENLEMI'].mean()\n",
        "      lon_center = df['VAKANIN BOYLAMI'].mean()\n",
        "\n",
        "      # Create density mapbox plot\n",
        "      fig = px.density_mapbox(df, lat='VAKANIN ENLEMI', lon='VAKANIN BOYLAMI', radius=radius,\n",
        "                              center=dict(lat=lat_center, lon=lon_center), zoom=10,\n",
        "                              mapbox_style=\"open-street-map\", opacity=0.7,\n",
        "                              color_continuous_scale=[\"blue\", \"yellow\", \"red\"],\n",
        "                              z='reach_time_scaled',\n",
        "                              animation_frame='week_day'\n",
        "                              )\n",
        "\n",
        "      # Update the layout with custom titles\n",
        "      fig.update_layout(\n",
        "          title=f\"VAKA YOĞUNLUK HARİTASI {day}, {most_common_month}. AY, {year}\",  # Main title\n",
        "          title_x=0.5,  # Center the title\n",
        "          coloraxis_colorbar=dict(\n",
        "              title=\"PUAN\",  # Color bar title\n",
        "          ),\n",
        "          geo=dict(\n",
        "              showland=True,  # Show land\n",
        "              landcolor=\"lightgray\"\n",
        "          )\n",
        "      )\n",
        "\n",
        "      # Adding the legacy as a text annotation\n",
        "      fig.add_annotation(\n",
        "          text=\"AVRUPA112 */ Muhammed KAYA\",\n",
        "          showarrow=False,\n",
        "          xref=\"paper\", yref=\"paper\",\n",
        "          x=0.95, y=0.05,  # Adjust position as needed\n",
        "          font=dict(size=12, color=\"black\")  # Adjust font size and color as needed\n",
        "      )\n",
        "\n",
        "      # Ensure day and year are converted to strings\n",
        "      filename = f'{most_common_month}_{str(day)}_{str(year)}_mapbox_graph.html'\n",
        "\n",
        "      file_path = str(input('Kaydetme Konumunu Seçiniz: ')) #'C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/finished_works/projections/daily_hourly_case_intensity/'\n",
        "\n",
        "      month_path = f'{file_path}/{str(year)}_{most_common_month}/'\n",
        "\n",
        "      if not os.path.exists(month_path):\n",
        "          os.makedirs(month_path)\n",
        "\n",
        "      # Save the graph as an HTML file in the specified directory\n",
        "      fig.write_html(os.path.join(month_path, filename))\n",
        "\n",
        "      # Print confirmation that the file was created successfully\n",
        "      print(f\"Graph saved successfully as {filename}\")\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"Failed to generate graph for {day}: {e}\")\n",
        "\n",
        "\n",
        "# Example function to generate graphs for all days of the week\n",
        "def generate_graphs_for_all_days(df):\n",
        "\n",
        "    year = df['Yıl'].unique()[0]  # Get the year\n",
        "\n",
        "    days_of_week = [\"PAZARTESİ\", \"SALI\", \"ÇARŞAMBA\", \"PERŞEMBE\", \"CUMA\", \"CUMARTESİ\", \"PAZAR\"]\n",
        "    for month in df['Ay'].unique():\n",
        "        filtered_df = df[df['Ay'] == month]\n",
        "        most_common_month = month  # Get the most frequent month\n",
        "\n",
        "        if not filtered_df.empty:\n",
        "          for day in days_of_week:\n",
        "              selected_df = filtered_df[filtered_df['Gün'] == day]\n",
        "              if not selected_df.empty:\n",
        "                  visualize_map(selected_df, day, most_common_month, year)\n",
        "\n",
        "generate_graphs_for_all_days(df)"
      ],
      "metadata": {
        "id": "nLwZ-3fm8W12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JBRpE9lu8W4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJn2joho8W6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1EwW4KOd8W8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EY6RGC808W_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6ktRSHG8XCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CaGGtnJ78XES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ifdYbUe28XGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1H6Kk-NE8XIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Tw6X2_WLHh3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(drop=True).to_csv('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/finished_works/projections/daily_hourly_case_intensity/anadolu_daily_hourly_case_intensity.csv', index=False)"
      ],
      "metadata": {
        "id": "1WkFCXzw8TpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_map(df, day, most_common_month, year):\n",
        "    try:\n",
        "        radius = 20 if len(df) < 15000 else 10\n",
        "        lat_center = df['VAKANIN ENLEMI'].mean()\n",
        "        lon_center = df['VAKANIN BOYLAMI'].mean()\n",
        "\n",
        "        # Create density mapbox plot\n",
        "        fig = px.density_mapbox(df, lat='VAKANIN ENLEMI', lon='VAKANIN BOYLAMI', radius=radius,\n",
        "                                center=dict(lat=lat_center, lon=lon_center), zoom=10,\n",
        "                                mapbox_style=\"open-street-map\", opacity=0.7,\n",
        "                                color_continuous_scale=[\"blue\", \"yellow\", \"red\"],\n",
        "                                z='reach_time_scaled',\n",
        "                                animation_frame='hour'\n",
        "                                )\n",
        "\n",
        "        # Update the layout with custom titles\n",
        "        fig.update_layout(\n",
        "            title=f\"VAKA YOĞUNLUK HARİTASI {day}, {most_common_month}. AY, {year}\",  # Main title\n",
        "            title_x=0.5,  # Center the title\n",
        "            coloraxis_colorbar=dict(\n",
        "                title=\"PUAN\",  # Color bar title\n",
        "            ),\n",
        "            geo=dict(\n",
        "                showland=True,  # Show land\n",
        "                landcolor=\"lightgray\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Adding the legacy as a text annotation\n",
        "        fig.add_annotation(\n",
        "            text=\"AVRUPA112 */ Muhammed KAYA\",\n",
        "            showarrow=False,\n",
        "            xref=\"paper\", yref=\"paper\",\n",
        "            x=0.95, y=0.05,  # Adjust position as needed\n",
        "            font=dict(size=12, color=\"black\")  # Adjust font size and color as needed\n",
        "        )\n",
        "\n",
        "        # Ensure day and year are converted to strings\n",
        "        filename = f'{most_common_month}_{str(day)}_{str(year)}_mapbox_graph.html'\n",
        "\n",
        "        file_path = 'C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/finished_works/projections/daily_hourly_case_intensity/'\n",
        "\n",
        "        month_path = f'{file_path}{str(year)}_{most_common_month}/'\n",
        "\n",
        "        if not os.path.exists(month_path):\n",
        "            os.makedirs(month_path)\n",
        "\n",
        "        # Save the graph as an HTML file in the specified directory\n",
        "        fig.write_html(os.path.join(month_path, filename))\n",
        "\n",
        "        # Print confirmation that the file was created successfully\n",
        "        print(f\"Graph saved successfully as {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to generate graph for {day}: {e}\")\n",
        "\n",
        "\n",
        "# Example function to generate graphs for all days of the week\n",
        "def generate_graphs_for_all_days(df):\n",
        "\n",
        "    year = df['Yıl'].unique()[0]  # Get the year\n",
        "\n",
        "    days_of_week = [\"PAZARTESİ\", \"SALI\", \"ÇARŞAMBA\", \"PERŞEMBE\", \"CUMA\", \"CUMARTESİ\", \"PAZAR\"]\n",
        "    for month in df['Ay'].unique():\n",
        "        filtered_df = df[df['Ay'] == month]\n",
        "        most_common_month = month  # Get the most frequent month\n",
        "\n",
        "        if not filtered_df.empty:\n",
        "          for day in days_of_week:\n",
        "              selected_df = filtered_df[filtered_df['Gün'] == day]\n",
        "              if not selected_df.empty:\n",
        "                  visualize_map(selected_df, day, most_common_month, year)\n",
        "\n",
        "generate_graphs_for_all_days(df)"
      ],
      "metadata": {
        "id": "jjNSalPoqJ1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_anadolu= df.copy()"
      ],
      "metadata": {
        "id": "psUDKdRMfBp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.concat([df_avrupa, df_anadolu])"
      ],
      "metadata": {
        "id": "1kHgGAiPfBsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_graphs_for_all_days(df)"
      ],
      "metadata": {
        "id": "529LTYrjfBuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values= temp_df.groupby(['İLÇE_ARGE','MAHALLE_ARGE','Ay','Gün','hour']).agg({'Value':'sum', 'reach_time':'mean', 'Longitude':'max', 'Latitude':'max'}).reset_index()\n",
        "daily_values= temp_df.groupby(['İLÇE_ARGE','MAHALLE_ARGE','Gün','hour']).agg({'Value':'sum', 'reach_time':'mean','Longitude':'max', 'Latitude':'max'}).reset_index()"
      ],
      "metadata": {
        "id": "OKcNdSTuvJGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "monthly_values= pd.merge(monthly_values, district_locations, on=['İLÇE_ARGE', 'MAHALLE_ARGE'], how='inner')\n",
        "daily_values= pd.merge(daily_values, district_locations, on=['İLÇE_ARGE', 'MAHALLE_ARGE'], how='inner')\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RpbSgIz8vJJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values"
      ],
      "metadata": {
        "id": "7jAoRDWId1i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OdL0mPiWP2bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values['reach_time']= monthly_values['reach_time'].fillna(0).round(2)\n",
        "daily_values['reach_time']= daily_values['reach_time'].fillna(0).round(2)"
      ],
      "metadata": {
        "id": "87kIOV1EvJMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_values['point']= daily_values['Value'] * daily_values['reach_time']\n",
        "monthly_values['point']= monthly_values['Value'] * monthly_values['reach_time']"
      ],
      "metadata": {
        "id": "kDzJF6XFvJOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values= monthly_values[(monthly_values['hour'] > 10) & (monthly_values['hour'] < 22)]\n",
        "daily_values= daily_values[(daily_values['hour'] > 10) & (daily_values['hour'] < 22)]"
      ],
      "metadata": {
        "id": "mBFdz_1FvJRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_values['point']= daily_values['point'].astype('float32')\n",
        "monthly_values['point']= monthly_values['point'].astype('float32')"
      ],
      "metadata": {
        "id": "TFXArz6lEU6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_values= daily_values[daily_values['point']>0]\n",
        "monthly_values= monthly_values[monthly_values['point']>0]"
      ],
      "metadata": {
        "id": "rlRImyscP27M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#district_locations.drop(columns='Value',inplace=True)"
      ],
      "metadata": {
        "id": "fLZPW7y6Q1Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_values.to_csv('daily_values.csv')\n",
        "monthly_values.to_csv('monthly_values.csv')"
      ],
      "metadata": {
        "id": "KPD7NAFdaAIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values.sort_values(by='point',ascending=False, inplace=True)\n",
        "daily_values.sort_values(by='point',ascending=False, inplace=True)"
      ],
      "metadata": {
        "id": "oeTsgE3Rc34m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values.duplicated().sum()"
      ],
      "metadata": {
        "id": "-Kw1HQ0cebaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values.to_csv('monthly_values.csv')\n",
        "daily_values.to_csv('daily_values.csv')"
      ],
      "metadata": {
        "id": "AgiJIYG4fSBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values= pd.read_csv('monthly_values.csv')\n",
        "daily_values= pd.read_csv('daily_values.csv')"
      ],
      "metadata": {
        "id": "17hsKzqzy4pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.offline as pyo\n",
        "\n",
        "df = daily_values\n",
        "\n",
        "# If columns exist, ensure they have the same length as other columns\n",
        "# If columns don't exist, create them or choose different columns for animation\n",
        "\n",
        "fig = px.scatter_mapbox(df, lat=\"Latitude\", lon=\"Longitude\", color=\"İLÇE_ARGE\", size=\"point\",size_max=15, zoom=10,color_continuous_scale=px.colors.cyclical.IceFire, animation_frame=['Gün','hour']) # Ensure 'Gün' and 'hour' are valid columns and have correct length\n",
        "\n",
        "fig.write_html('test.html')"
      ],
      "metadata": {
        "id": "vdoofZVkvFj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values['point'].describe()"
      ],
      "metadata": {
        "id": "NU6RBxVAgKxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "-(monthly_values['point'].mean()-monthly_values['point'].max()) / 2"
      ],
      "metadata": {
        "id": "LIJnk9HLyzSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "\n",
        "# Function to map point values to colors\n",
        "def get_marker_color(point):\n",
        "    if point < 440:\n",
        "        return 'green'\n",
        "    elif point < 701:\n",
        "        return 'blue'\n",
        "    elif point < 1172:\n",
        "        return 'orange'\n",
        "    else:\n",
        "        return 'red'\n",
        "\n",
        "# Load your dataset\n",
        "df = monthly_values\n",
        "\n",
        "# Use a subset of the data for performance (or full data if needed)\n",
        "subset_df = df.sample(500)\n",
        "\n",
        "# Create a map centered around the mean coordinates of the dataset\n",
        "map_center = [subset_df['Latitude'].mean(), subset_df['Longitude'].mean()]\n",
        "ambulance_map = folium.Map(location=map_center, zoom_start=11)\n",
        "\n",
        "# Add markers for each location with color based on point values\n",
        "for _, row in subset_df.iterrows():\n",
        "    marker_color = get_marker_color(row['point'])\n",
        "\n",
        "    folium.Marker(\n",
        "        location=[row['Latitude'], row['Longitude']],\n",
        "        popup=(f\"District: {row['İLÇE_ARGE']}<br>\"\n",
        "               f\"Neighborhood: {row['MAHALLE_ARGE']}<br>\"\n",
        "               f\"Month: {row['Ay']}<br>\"\n",
        "               f\"Day: {row['Gün']}<br>\"\n",
        "               f\"Hour: {row['hour']}<br>\"\n",
        "               f\"Point: {row['point']}\"),\n",
        "        icon=folium.Icon(color=marker_color)\n",
        "    ).add_to(ambulance_map)\n",
        "\n",
        "# Save the map as an HTML file\n",
        "ambulance_map.save('ambulance_map.html')\n"
      ],
      "metadata": {
        "id": "6J71g_ZHgKzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-bIaZqzEkwet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_of_week = ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA', 'CUMARTESİ', 'PAZAR']\n",
        "monthly_values['Gün'] = pd.Categorical(monthly_values['Gün'], categories=day_of_week, ordered=True)"
      ],
      "metadata": {
        "id": "n2B2oPau4Ecy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hivul9Hx4HEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values.sort_values(by=['İLÇE_ARGE', 'MAHALLE_ARGE', 'Ay', 'Gün', 'hour', 'Value'], ascending=[True, True, True, True, True, False], inplace=True)"
      ],
      "metadata": {
        "id": "LszZU-ZEgK1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values.drop(columns='Unnamed: 0', inplace=True)"
      ],
      "metadata": {
        "id": "alcWga-2gK4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "AGdNo_-pgK54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values"
      ],
      "metadata": {
        "id": "FeP-3VCzgK8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import altair as alt\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from matplotlib.animation import FFMpegWriter\n",
        "from altair_saver import save\n",
        "\n",
        "# Read the CSV file\n",
        "df =pd.read_csv('monthly_values.csv')\n",
        "\n",
        "# Get unique combinations of month, day, and hour\n",
        "combinations = df[['Ay', 'Gün', 'hour']].drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# Function to update the plot for each animation frame\n",
        "def update(i):\n",
        "    # Filter data for the current frame\n",
        "    filtered_df = df[(df['Ay'] == combinations.loc[i, 'Ay']) &\n",
        "                     (df['Gün'] == combinations.loc[i, 'Gün']) &\n",
        "                     (df['hour'] == combinations.loc[i, 'hour'])]\n",
        "\n",
        "    # Create the scatter plot using Altair\n",
        "    chart = alt.Chart(filtered_df).mark_circle().encode(\n",
        "        x='Longitude',\n",
        "        y='Latitude',\n",
        "        tooltip=['Longitude', 'Latitude']\n",
        "    ).properties(\n",
        "        title=f\"Month: {combinations.loc[i, 'Ay']}, Day: {combinations.loc[i, 'Gün']}, Hour: {combinations.loc[i, 'hour']}\"\n",
        "    ).interactive()\n",
        "\n",
        "    # Save the chart as an image\n",
        "    save(chart, f\"temp_chart_{i}.png\")\n",
        "\n",
        "    # Read the image using Matplotlib\n",
        "    img = plt.imread(f\"temp_chart_{i}.png\")\n",
        "\n",
        "    # Display the image in the animation\n",
        "    return plt.imshow(img)\n",
        "\n",
        "# Create the animation using Matplotlib\n",
        "fig = plt.figure()\n",
        "ani = animation.FuncAnimation(fig, update, frames=len(combinations), interval=500)\n",
        "\n",
        "# Create an FFMpegWriter object\n",
        "writer = FFMpegWriter(fps=5)  # Adjust fps as needed\n",
        "\n",
        "# Save the animation using the FFMpegWriter\n",
        "ani.save('location_animation.mp4', writer=writer)\n",
        "\n",
        "# Display a message\n",
        "print(\"Animation saved as location_animation.mp4\")"
      ],
      "metadata": {
        "id": "IJTSYoU8gK-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7c-bihAEgLA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ezbr_ov0gLCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kq-RlAYDgLE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_continuous_scale=px.colors.cyclical.IceFire"
      ],
      "metadata": {
        "id": "M3MtpTgmvFol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "9MzEHCvNvFvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unfinished_works_path= 'C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/data/unfinished_works/'"
      ],
      "metadata": {
        "id": "ufQ2oBHpVHaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_values= pd.read_csv(unfinished_works_path+'daily_values.csv')\n",
        "monthly_values= pd.read_csv(unfinished_works_path+'monthly_values.csv')"
      ],
      "metadata": {
        "id": "gzbDfnPXdJUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_values.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "monthly_values.drop(columns=['Unnamed: 0'], inplace=True)"
      ],
      "metadata": {
        "id": "fbHhLUpNdJWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: drop duplicated rows\n",
        "monthly_values.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "q6y9mivZjlwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_of_week = ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA', 'CUMARTESİ', 'PAZAR']\n",
        "monthly_values['Gün'] = pd.Categorical(monthly_values['Gün'], categories=day_of_week, ordered=True)"
      ],
      "metadata": {
        "id": "Cf2bswEj-20N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values.drop_duplicates(keep='first').sort_values('point', ascending=False).head(50)"
      ],
      "metadata": {
        "id": "gMt20glrjyMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values= pd.read_csv('monthly_values.csv')"
      ],
      "metadata": {
        "id": "nx9rMRhj8zAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.offline as pyo\n",
        "\n",
        "df = monthly_values.copy()\n",
        "# If columns exist, ensure they have the same length as other columns\n",
        "# If columns don't exist, create them or choose different columns for animation\n",
        "\n",
        "fig = px.scatter_mapbox(df, lat=\"Latitude\", lon=\"Longitude\", color=\"İLÇE_ARGE\", size=\"point\",size_max=15, zoom=10,color_continuous_scale=px.colors.cyclical.IceFire, animation_frame='Ay', animation_group='Gün') # Ensure 'Gün' and 'hour' are valid columns and have correct length\n",
        "\n",
        "# Save the figure using plot\n",
        "fig.write_html('test.html')"
      ],
      "metadata": {
        "id": "_c8-v9WhdJbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample = df.head(100)  # Adjust the number of rows as needed\n",
        "fig = px.scatter_mapbox(df_sample, lat=\"Latitude\", lon=\"Longitude\", color=\"İLÇE_ARGE\", size=\"point\", size_max=15, zoom=10, color_continuous_scale=px.colors.cyclical.IceFire, animation_frame=['Ay','Gün','hour'])\n",
        "fig.write_html('test_sample.html')\n"
      ],
      "metadata": {
        "id": "MlZiBC4Y_dFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a combined column for animation\n",
        "df_sample['animation_frame'] = df_sample['Ay'].astype(str) + '-' + df_sample['Gün'].astype(str) + '-' + df_sample['hour'].astype(str)\n",
        "\n",
        "# Use the combined column for animation\n",
        "fig = px.scatter_mapbox(df_sample,\n",
        "                       lat=\"Latitude\",\n",
        "                       lon=\"Longitude\",\n",
        "                       color=\"İLÇE_ARGE\",\n",
        "                       size=\"point\",\n",
        "                       size_max=15,\n",
        "                       zoom=10,\n",
        "                       color_continuous_scale=px.colors.cyclical.IceFire,\n",
        "                       animation_frame='animation_frame')  # Use the combined column for animation\n",
        "\n",
        "fig.write_html('test.html')"
      ],
      "metadata": {
        "id": "f0-6utE2_xXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[['Ay', 'Gün', 'hour']].info())\n",
        "print(df[['Latitude', 'Longitude', 'point']].info())\n"
      ],
      "metadata": {
        "id": "VBtK73jl-rmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[['Ay', 'Gün', 'hour']].isnull().sum())\n"
      ],
      "metadata": {
        "id": "CQ2WnRFx-yE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[['Ay', 'Gün', 'hour']].dtypes)\n"
      ],
      "metadata": {
        "id": "UQxWWosr-yHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Assuming df is your main DataFrame\n",
        "def generate_map(df):\n",
        "    # Step 1: Select İLÇE_ARGE\n",
        "    ilce_values = df['İLÇE_ARGE'].unique()\n",
        "    print(f\"Available İLÇE_ARGE values: {ilce_values}\")\n",
        "    selected_ilce = input(\"Select an İLÇE_ARGE: \")\n",
        "\n",
        "    # Step 2: Filter available MAHALLE_ARGE for selected İLÇE_ARGE\n",
        "    mahalle_values = df[df['İLÇE_ARGE'] == selected_ilce]['MAHALLE_ARGE'].unique()\n",
        "    if len(mahalle_values) == 0:\n",
        "        print(f\"No MAHALLE_ARGE found for İLÇE_ARGE: {selected_ilce}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Available MAHALLE_ARGE values in {selected_ilce}: {mahalle_values}\")\n",
        "    selected_mahalle = input(\"Select a MAHALLE_ARGE: \")\n",
        "\n",
        "    # Step 3: Filter the DataFrame based on selected İLÇE_ARGE and MAHALLE_ARGE\n",
        "    filtered_df = df[(df['İLÇE_ARGE'] == selected_ilce) & (df['MAHALLE_ARGE'] == selected_mahalle)]\n",
        "\n",
        "    # Step 4: Ask for the month (Ay)\n",
        "    ay_values = filtered_df['Ay'].unique()\n",
        "    print(f\"Available months (Ay): {ay_values}\")\n",
        "    selected_ay = input(\"Select a month (Ay): \")\n",
        "\n",
        "    # Filter the DataFrame further by the selected month\n",
        "    filtered_df = filtered_df[filtered_df['Ay'] == selected_ay]\n",
        "\n",
        "    # Check if any data is available for the selected values\n",
        "    if filtered_df.empty:\n",
        "        print(\"No data available for the selected İLÇE_ARGE, MAHALLE_ARGE, and Ay.\")\n",
        "        return\n",
        "\n",
        "    # Step 5: Create hourly mapbox with daily animation frame\n",
        "    fig = px.scatter_mapbox(filtered_df,\n",
        "                            lat=\"Latitude\",\n",
        "                            lon=\"Longitude\",\n",
        "                            color=\"point\",\n",
        "                            size=\"point\",\n",
        "                            size_max=15,\n",
        "                            zoom=10,\n",
        "                            color_continuous_scale=px.colors.cyclical.IceFire,\n",
        "                            animation_frame='Gün',  # Animate by 'Gün' (daily)\n",
        "                            animation_group='hour')  # Group by 'hour' (hourly data)\n",
        "\n",
        "    # Show or save the figure\n",
        "    fig.write_html('filtered_map.html')\n",
        "    print(\"Map saved as 'filtered_map.html'.\")\n",
        "\n",
        "# Example usage\n",
        "generate_map(df)\n"
      ],
      "metadata": {
        "id": "jpEYZb8h-yJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mUU0TaGsbmAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vunWTUfEbmDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "NAA0-4tAbmGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values= pd.read_csv('monthly_values.csv')"
      ],
      "metadata": {
        "id": "ql8GfMnbbxkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values.head()"
      ],
      "metadata": {
        "id": "_wyZrhGTdIkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values.drop(columns=['Unnamed: 0'], inplace=True)"
      ],
      "metadata": {
        "id": "lwzbad59dRZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values['İLÇE_ARGE']= monthly_values['İLÇE_ARGE'].astype(str).str.strip()\n",
        "monthly_values['MAHALLE_ARGE']= monthly_values['MAHALLE_ARGE'].astype(str).str.strip()\n",
        "monthly_values['Ay']= monthly_values['Ay'].astype(int)\n",
        "monthly_values['Gün']= monthly_values['Gün'].astype(str).str.strip()\n",
        "monthly_values['hour']= monthly_values['hour'].astype(int)\n",
        "monthly_values['point']= monthly_values['point'].astype('float32')\n",
        "monthly_values['reach_time']= monthly_values['reach_time'].astype('float32')"
      ],
      "metadata": {
        "id": "vQSRSz-pdRb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_of_week= ['PAZARTESİ', 'SALI', 'ÇARŞAMBA', 'PERŞEMBE', 'CUMA', 'CUMARTESİ', 'PAZAR']\n",
        "monthly_values['Gün'] = pd.Categorical(monthly_values['Gün'], categories=day_of_week, ordered=True)"
      ],
      "metadata": {
        "id": "6dydrK7EdRd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c6846JeOdRgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LSL5WCv3dH91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_map(monthly_values):\n",
        "  monthly_values['İLÇE_ARGE']= monthly_values['İLÇE_ARGE'].astype(str).str.strip()\n",
        "  monthly_values['MAHALLE_ARGE']= monthly_values['MAHALLE_ARGE'].astype(str).str.strip()\n",
        "  monthly_values['Ay']= monthly_values['Ay'].astype(int)\n",
        "  monthly_values['Gün']= monthly_values['Gün'].astype(str).str.strip()\n",
        "  monthly_values['hour']= monthly_values['hour'].astype(int)\n",
        "  monthly_values['point']= monthly_values['point'].astype('float32')\n",
        "  monthly_values['reach_time']= monthly_values['reach_time'].astype('float32')\n",
        "  monthly_values['Latitude']= monthly_values['Latitude'].astype('float32')\n",
        "  monthly_values['Longitude']= monthly_values['Longitude'].astype('float32')\n",
        "\n",
        "  selected_district= monthly_values.copy()\n",
        "\n",
        "  print(selected_district['Ay'].unique())\n",
        "  month= int(input('Enter a month: '))\n",
        "\n",
        "  if month not in selected_district['Ay'].unique():\n",
        "    print('Month not found')\n",
        "    return generate_map(df)\n",
        "  else:\n",
        "    selected_district= selected_district[selected_district['Ay']==month]\n",
        "\n",
        "  print(selected_district['Gün'].unique())\n",
        "  day= str(input('Enter a day: '))\n",
        "\n",
        "  if day not in selected_district['Gün'].unique():\n",
        "    print('Day not found')\n",
        "    return generate_map(df)\n",
        "\n",
        "  else:\n",
        "    selected_district= selected_district[selected_district['Gün']==day]\n",
        "    return selected_district\n",
        "\n",
        "selected_df= generate_map(monthly_values)\n",
        "\n",
        "\n",
        "def visualize_map(df):\n",
        "  #district_name= df['İLÇE_ARGE'].unique()[0]\n",
        "  #neighborhood_name= df['MAHALLE_ARGE'].unique()[0]\n",
        "  month_name= df['Ay'].unique()[0]\n",
        "  day_name= df['Gün'].unique()[0]\n",
        "\n",
        "  fig = px.scatter_mapbox(df, lat=\"Latitude\", lon=\"Longitude\", color=\"İLÇE_ARGE\", size=\"point\", size_max=15, zoom=10, color_continuous_scale=px.colors.cyclical.IceFire, animation_frame='hour')\n",
        "  fig.update_layout(mapbox_style=\"open-street-map\")\n",
        "  fig.write_html(f'Ay_{month_name}_Gun_{day_name}.html')\n",
        "  #fig.update_layout(mapbox_style= \"carto-positron\")\n",
        "  fig.show()\n",
        "visualize_map(selected_df)\n"
      ],
      "metadata": {
        "id": "ywhc_xn0YI61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_df[['Latitude', 'Longitude']].describe())  # Check ranges of Latitude and Longitude"
      ],
      "metadata": {
        "id": "GL4_-9cdYI9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import json\n",
        "\n",
        "# Load your GeoJSON file, specifying the encoding as UTF-8\n",
        "with open('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/data/locations/istanbul_neighbourhoods.geojson', encoding='utf-8') as f:\n",
        "    geojson_data = json.load(f)\n",
        "\n",
        "def visualize_geojson_optimized(geojson_data):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add GeoJSON data as a trace\n",
        "    for feature in geojson_data['features']:\n",
        "        geometry_type = feature['geometry']['type']\n",
        "        coordinates = feature['geometry']['coordinates']\n",
        "\n",
        "        if geometry_type == 'Point':\n",
        "            lons, lats = coordinates\n",
        "            fig.add_trace(go.Scattermapbox(\n",
        "                mode='markers',\n",
        "                lon=[lons],\n",
        "                lat=[lats],\n",
        "                marker=dict(size=10, color='blue'),\n",
        "                showlegend=False\n",
        "            ))\n",
        "\n",
        "        elif geometry_type == 'LineString':\n",
        "            lons, lats = zip(*coordinates)\n",
        "            fig.add_trace(go.Scattermapbox(\n",
        "                mode='lines',\n",
        "                lon=lons,\n",
        "                lat=lats,\n",
        "                line=dict(width=2, color='blue'),\n",
        "                showlegend=False\n",
        "            ))\n",
        "\n",
        "        elif geometry_type == 'Polygon':\n",
        "            lons, lats = zip(*coordinates[0])  # Assuming single ring for simplicity\n",
        "            fig.add_trace(go.Scattermapbox(\n",
        "                mode='lines',\n",
        "                lon=lons,\n",
        "                lat=lats,\n",
        "                line=dict(width=2, color='blue'),\n",
        "                fill='toself',\n",
        "                fillcolor='rgba(0, 0, 255, 0.2)',\n",
        "                showlegend=False\n",
        "            ))\n",
        "\n",
        "        elif geometry_type == 'MultiPolygon':\n",
        "            for polygon in coordinates:\n",
        "                for ring in polygon:\n",
        "                    lons, lats = zip(*ring)\n",
        "                    fig.add_trace(go.Scattermapbox(\n",
        "                        mode='lines',\n",
        "                        lon=lons,\n",
        "                        lat=lats,\n",
        "                        line=dict(width=2, color='blue'),\n",
        "                        fill='toself',\n",
        "                        fillcolor='rgba(0, 0, 255, 0.2)',\n",
        "                        showlegend=False\n",
        "                    ))\n",
        "\n",
        "    fig.update_layout(mapbox_style=\"carto-positron\")\n",
        "\n",
        "    # Optimize layout and interactivity\n",
        "    fig.update_layout(\n",
        "        mapbox=dict(\n",
        "            style=\"carto-positron\",\n",
        "            center=dict(lat=37.7749, lon=-122.4194),  # Set to your preferred center\n",
        "            zoom=10  # Adjust zoom level as needed\n",
        "        ),\n",
        "        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}  # Remove margins for better fit\n",
        "    )\n",
        "\n",
        "    fig.write_html('mapgraph.html')\n",
        "# Example usage\n",
        "visualize_geojson_optimized(geojson_data)"
      ],
      "metadata": {
        "id": "-LdYvcwJYI-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import json"
      ],
      "metadata": {
        "id": "NFaD31FIYJBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/data/locations/istanbul_neighbourhoods.geojson', encoding='utf-8') as f: # Added encoding='utf-8' to handle different file encodings\n",
        "    geojson_data = json.load(f)"
      ],
      "metadata": {
        "id": "PmX-OC2a4I2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geojson_data.keys()"
      ],
      "metadata": {
        "id": "K-Q1hiXLYJDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geojson_data"
      ],
      "metadata": {
        "id": "GvVGH1Qy3ovp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HuHnUDka4fND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3fVsdzOy4fPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_values= pd.read_csv('monthly_values.csv')\n",
        "df= monthly_values.copy()"
      ],
      "metadata": {
        "id": "dphmBfu_4fSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import json\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from shapely.geometry import shape, Point, Polygon\n",
        "from shapely.geometry.multipolygon import MultiPolygon\n",
        "\n",
        "# Load your GeoJSON file\n",
        "with open('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/data/locations/istanbul_neighbourhoods.geojson', encoding='utf-8') as f: # Added encoding='utf-8' to handle different file encodings\n",
        "    geojson_data = json.load(f)\n",
        "\n",
        "def extract_polygons(geojson_data):\n",
        "    \"\"\"Extract polygons from a GeoJSON file\"\"\"\n",
        "    polygons = []\n",
        "    for feature in geojson_data['features']:\n",
        "        geom_type = feature['geometry']['type']\n",
        "        coordinates = feature['geometry']['coordinates']\n",
        "        if geom_type == 'Polygon':\n",
        "            # Ensure coordinates is a list of lists\n",
        "            if isinstance(coordinates[0][0], list):\n",
        "                polygons.append(Polygon(coordinates))\n",
        "            else:\n",
        "                polygons.append(Polygon([coordinates]))\n",
        "        elif geom_type == 'MultiPolygon':\n",
        "            for poly_coords in coordinates:\n",
        "                # Ensure each coordinates set is in the correct format\n",
        "                if isinstance(poly_coords[0][0], list):\n",
        "                    polygons.append(Polygon(poly_coords))\n",
        "                else:\n",
        "                    polygons.append(Polygon([poly_coords]))\n",
        "    return polygons\n",
        "\n",
        "def get_polygon_color(avg_point_value, min_val, max_val):\n",
        "    \"\"\"Map an aggregated point value to a color in a gradient from blue to red\"\"\"\n",
        "    if np.isnan(avg_point_value):  # Handle NaN values\n",
        "        return 'rgba(0, 0, 0, 0)'  # Default color (e.g., transparent)\n",
        "    normalized = (avg_point_value - min_val) / (max_val - min_val)\n",
        "    normalized = np.clip(normalized, 0, 1)  # Ensure value is within [0, 1]\n",
        "    return px.colors.sequential.RdBu[int(normalized * (len(px.colors.sequential.RdBu) - 1))]\n",
        "\n",
        "def visualize_map_with_geojson(df, geojson_data):\n",
        "    if df.empty:\n",
        "        print(\"No data to visualize.\")\n",
        "        return\n",
        "\n",
        "    # Prepare polygons\n",
        "    polygons = extract_polygons(geojson_data)\n",
        "\n",
        "    # Create a DataFrame to hold average point values for each polygon\n",
        "    polygon_values = []\n",
        "\n",
        "    for feature in geojson_data['features']:\n",
        "        geom = shape(feature['geometry'])\n",
        "        # Collect points inside the current polygon\n",
        "        points_inside = df[df.apply(lambda row: geom.contains(Point(row['Longitude'], row['Latitude'])), axis=1)]\n",
        "        # Calculate the average point value for the polygon\n",
        "        avg_point_value = points_inside['point'].mean() if not points_inside.empty else np.nan\n",
        "        polygon_values.append({\n",
        "            'geometry': geom,\n",
        "            'avg_point_value': avg_point_value,\n",
        "            'properties': feature['properties']\n",
        "        })\n",
        "\n",
        "    # Compute min and max points for color scaling, ignoring NaNs\n",
        "    point_values = [pv['avg_point_value'] for pv in polygon_values if not np.isnan(pv['avg_point_value'])]\n",
        "    min_point = min(point_values) if point_values else 0\n",
        "    max_point = max(point_values) if point_values else 1\n",
        "\n",
        "    # Create the figure\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add GeoJSON polygons to the map with color gradient\n",
        "    for pv in polygon_values:\n",
        "        if pv['geometry'].is_empty:\n",
        "            continue\n",
        "        lons, lats = zip(*list(pv['geometry'].exterior.coords))\n",
        "        color = get_polygon_color(pv['avg_point_value'], min_point, max_point)\n",
        "        fig.add_trace(go.Scattermapbox(\n",
        "            mode='lines',\n",
        "            lon=lons + (lons[0],),  # Close the polygon\n",
        "            lat=lats + (lats[0],),  # Close the polygon\n",
        "            line=dict(width=2, color=color),\n",
        "            fill='toself',\n",
        "            fillcolor=f'rgba{color[4:]}',  # Fill color with transparency\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(mapbox_style=\"carto-positron\")\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "# Example usage\n",
        "selected_df = generate_map(monthly_values)  # Your previous data filtering function\n",
        "visualize_map_with_geojson(selected_df, geojson_data)\n"
      ],
      "metadata": {
        "id": "j3LSNWo1YJFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shapely.geometry import shape, Polygon\n",
        "import json\n",
        "\n",
        "def extract_polygons(geojson_data):\n",
        "    \"\"\"Extract polygons from a GeoJSON file\"\"\"\n",
        "    polygons = []\n",
        "    for feature in geojson_data['features']:\n",
        "        geom_type = feature['geometry']['type']\n",
        "        coordinates = feature['geometry']['coordinates']\n",
        "        if geom_type == 'Polygon':\n",
        "            if isinstance(coordinates[0][0], list):\n",
        "                polygons.append(Polygon(coordinates))\n",
        "            else:\n",
        "                # Ensure coordinates are in the expected format\n",
        "                polygons.append(Polygon([coordinates]))\n",
        "        elif geom_type == 'MultiPolygon':\n",
        "            for poly_coords in coordinates:\n",
        "                if isinstance(poly_coords[0][0], list):\n",
        "                    polygons.append(Polygon(poly_coords))\n",
        "                else:\n",
        "                    polygons.append(Polygon([poly_coords]))\n",
        "    return polygons\n"
      ],
      "metadata": {
        "id": "6-3NEOS3YJH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your GeoJSON file\n",
        "with open('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/data/locations/istanbul_neighbourhoods.geojson', encoding='utf-8') as f: # Added encoding='utf-8' to handle different file encodings\n",
        "    geojson_data = json.load(f)\n",
        "\n",
        "# Test polygon extraction\n",
        "polygons = extract_polygons(geojson_data)\n",
        "print(f\"Extracted {len(polygons)} polygons.\")"
      ],
      "metadata": {
        "id": "9raW0fqtD79N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shapely.geometry import shape, Polygon, MultiPolygon\n",
        "\n",
        "def extract_polygons(geojson_data):\n",
        "    \"\"\"Extract polygons from a GeoJSON file\"\"\"\n",
        "    polygons = []\n",
        "    for feature in geojson_data['features']:\n",
        "        geom_type = feature['geometry']['type']\n",
        "        coordinates = feature['geometry']['coordinates']\n",
        "        if geom_type == 'Polygon':\n",
        "            # Handle Polygon coordinates, should be a list of lists\n",
        "            if isinstance(coordinates[0][0], list):\n",
        "                polygons.append(Polygon(coordinates))\n",
        "            else:\n",
        "                # Handle cases where coordinates might be incorrectly formatted\n",
        "                polygons.append(Polygon([coordinates]))\n",
        "        elif geom_type == 'MultiPolygon':\n",
        "            # Handle MultiPolygon by creating individual Polygons\n",
        "            for poly_coords in coordinates:\n",
        "                if isinstance(poly_coords[0][0], list):\n",
        "                    polygons.append(Polygon(poly_coords))\n",
        "                else:\n",
        "                    polygons.append(Polygon([poly_coords]))\n",
        "    return polygons\n"
      ],
      "metadata": {
        "id": "hpl4RuudENKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load your GeoJSON file\n",
        "with open('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/data/locations/istanbul_neighbourhoods.geojson', encoding='utf-8') as f: # Added encoding='utf-8' to handle different file encodings\n",
        "    geojson_data = json.load(f)\n",
        "\n",
        "# Test polygon extraction\n",
        "try:\n",
        "    polygons = extract_polygons(geojson_data)\n",
        "    print(f\"Extracted {len(polygons)} polygons.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during extraction: {e}\")\n"
      ],
      "metadata": {
        "id": "nJGUIqNTENMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jWOZhyg0ENO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hILPNSEkENQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DM--wsaLENTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2zJDGnRKENVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "-R20qMXR-yK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GH68GzZ2-yNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zHqCtXZN-yPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values(by='point', ascending=False)"
      ],
      "metadata": {
        "id": "RKi7IxIQdJdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xKFozpnEdJfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3LeYYpSudJhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2l15BS_ydJlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bwCkt9vbdJnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3sxa7mpdJp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_OJp4YUpdJst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3mbNiQRUdJuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTqLDsNVvFxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import bson\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from shapely.geometry import shape\n",
        "\n",
        "# Load the JSON metadata\n",
        "with open('C:/Users/mkaya/OneDrive/Masaüstü/istanbul112_hidden/data/locations/api_database/neighborhoods.metadata.json') as json_file:\n",
        "    metadata = json.load(json_file)\n",
        "\n",
        "# Load the BSON file\n",
        "with open('C:/Users/mkaya/OneDrive/Masaüstü/istanbul112_hidden/data/locations/api_database/neighborhoods.bson', 'rb') as bson_file:\n",
        "    neighborhoods = bson.decode_all(bson_file.read())\n",
        "\n",
        "# Convert the BSON data to a DataFrame\n",
        "df = pd.DataFrame(neighborhoods)\n",
        "\n",
        "# Assuming the BSON data has a field with the geometry\n",
        "# Convert the geometry to GeoPandas GeoSeries\n",
        "gdf = gpd.GeoDataFrame(df, geometry=df['_id'].apply(shape))\n"
      ],
      "metadata": {
        "id": "szDIPWPzDVj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata"
      ],
      "metadata": {
        "id": "9_amwAmwEEYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['city']=='İstanbul']"
      ],
      "metadata": {
        "id": "83Fi4PG0Dsvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVVp6UJlDVmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8y5kHTX7DVob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RIhElvJoDVqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kCYt2BEXDVsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXVqcw64DVua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s036NF_3DV80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x1AqYMFWDV_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tZHDyIPYDWBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZQx29n3DWDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uBVmCe2yDWF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dPK8AssHDWH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7234CCwlDWKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wfapMSX1DWMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Crr8OGRyDWOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ha3HrU0RDWQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "arltHLclDWTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BIbmxNnFDWVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pi3RQ89BDWX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CpqHzo1DDWbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_pivot['TOPLAM']= hour_pivot.sum(axis=1)"
      ],
      "metadata": {
        "id": "u1n5VJru4u69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sort hour_pivot Gün by day_of_week\n",
        "\n",
        "hour_pivot = hour_pivot.reindex(columns=day_of_week, level='Gün')\n"
      ],
      "metadata": {
        "id": "0yKAOl_JDXX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_pivot= hour_pivot.reindex(columns=day_of_week, level='Gün').reset_index().fillna(0)"
      ],
      "metadata": {
        "id": "fIKgUa5FDXaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_pivot.to_excel('saatlik_vaka_sayisi.xlsx')"
      ],
      "metadata": {
        "id": "4Fpc2EgVUDXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hour_pivot"
      ],
      "metadata": {
        "id": "fMKEJ2VPDXcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations= pd.read_excel('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/data/locations/station_locations.xlsx')"
      ],
      "metadata": {
        "id": "dfXWW00tDXem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations['latitude']= station_locations['KOORDİNAT'].apply(lambda x: x.split(',')[0])\n",
        "station_locations['longitude']= station_locations['KOORDİNAT'].apply(lambda x: x.split(',')[1])\n",
        "station_locations.drop(columns=['KOORDİNAT'], inplace=True)"
      ],
      "metadata": {
        "id": "k8LTcLdrnNzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station_locations.rename(columns={'Ekip Adı':'EKIP NO'}, inplace=True)"
      ],
      "metadata": {
        "id": "Nr-MGRLo87YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df= pd.merge(temp_df, station_locations, on='EKIP NO', how='inner')"
      ],
      "metadata": {
        "id": "jOUr3JU6nN12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_team_cases= temp_df.pivot_table(index= ['EKIP NO','Saat Aralığı'], columns=['Ay','Gün'], values='Value', aggfunc='sum').fillna(0)"
      ],
      "metadata": {
        "id": "GUIdsTvYnN4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_of_week"
      ],
      "metadata": {
        "id": "Z_xlLiFxnN6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_team_cases"
      ],
      "metadata": {
        "id": "BLxbeZlbnN80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_team_cases= hourly_team_cases.reindex(columns=day_of_week, level='Gün').reset_index().fillna(0)"
      ],
      "metadata": {
        "id": "iRI2XEiMnN_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_team_cases"
      ],
      "metadata": {
        "id": "8GKYtV7hEzp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_team_cases.to_excel('ekip_bazli_saatlik_vaka.xlsx')"
      ],
      "metadata": {
        "id": "exWZJWlUnO24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.rename(columns={'EKIP NO':'team'})"
      ],
      "metadata": {
        "id": "mnH7yYivEJFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_team_cases"
      ],
      "metadata": {
        "id": "EFUiiRwdL4VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a column of temp_df named hourly_case and check hourly team cases, add the value of the hourly_team_cases where equal to temp_df on EKIP NO , Gün, Ay, Saat Aralığı\n",
        "\n",
        "temp_df['hourly_case'] = 0\n",
        "for index, row in temp_df.iterrows():\n",
        "  team = row['EKIP NO']\n",
        "  gun = row['Gün']\n",
        "  ay = row['Ay']\n",
        "  saat = row['Saat Aralığı']\n",
        "  hourly_case = hourly_team_cases[(hourly_team_cases['EKIP NO'] == team) & (hourly_team_cases['Gün'] == gun) & (hourly_team_cases['Ay'] == ay) & (hourly_team_cases['Saat Aralığı'] == saat)].iloc[0, 4:].sum()\n",
        "  temp_df.at[index, 'hourly_case'] = hourly_case\n"
      ],
      "metadata": {
        "id": "kDTgjUGhFC5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from geopy.distance import great_circle\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'team': ['A', 'B', 'C', 'D'],\n",
        "    'latitude': [41.015137, 41.025137, 41.035137, 41.045137],\n",
        "    'longitude': [28.979530, 28.989530, 28.999530, 29.009530],\n",
        "    'hourly_cases': [1.5, 0.8, 0.6, 1.3]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Thresholds\n",
        "case_threshold = 1.2\n",
        "\n",
        "# Function to calculate the distance between two points\n",
        "def calculate_distance(lat1, lon1, lat2, lon2):\n",
        "    return great_circle((lat1, lon1), (lat2, lon2)).kilometers\n",
        "\n",
        "# Identify teams with case load under the threshold\n",
        "underloaded_teams = df[df['hourly_cases'] < case_threshold]\n",
        "\n",
        "# Function to find the closest team for overloaded teams\n",
        "def find_closest_team(overloaded_team):\n",
        "    overloaded_lat = overloaded_team['latitude']\n",
        "    overloaded_lon = overloaded_team['longitude']\n",
        "\n",
        "    # Calculate distance to all underloaded teams\n",
        "    underloaded_teams['distance'] = underloaded_teams.apply(\n",
        "        lambda row: calculate_distance(overloaded_lat, overloaded_lon, row['latitude'], row['longitude']), axis=1)\n",
        "\n",
        "    # Find the closest team\n",
        "    closest_team = underloaded_teams.loc[underloaded_teams['distance'].idxmin()]\n",
        "    return closest_team\n",
        "\n",
        "# Iterate over teams with a case load over the threshold\n",
        "for index, overloaded_team in df[df['hourly_cases'] > case_threshold].iterrows():\n",
        "    closest_team = find_closest_team(overloaded_team)\n",
        "    print(f\"Team {overloaded_team['team']} is overloaded. The closest team is {closest_team['team']} with {closest_team['hourly_cases']} cases.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "tOiIoZfPnPFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pPU0Y1y-nPH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "48ts3QTvnPKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GvvrYiXQDXgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jxsNZfWtDXjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vc663oId9Bmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xKipHBI39Bo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8BYBwu6b9Bq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UTqee73kk9bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: set colors of fig for False = Red , for True= Blue and by 'Ay'\n",
        "dff = temp_df.copy()\n",
        "fig = px.scatter_mapbox(dff, lat=\"ENLEM\", lon=\"BOYLAM\", color=\"Gecikme\", size=\"Aylık Vaka Sayısı\",hover_data=['Ortalama Vaka Süresi'],hover_name='Mahalle Adı',\n",
        "                  color_discrete_map={'Yok':'blue','Var':'red'}, size_max=15, zoom=10, animation_frame='Ay',\n",
        "                  mapbox_style=\"carto-positron\")\n",
        "fig.write_html(\"C:/Users/mkaya/Onedrive/Masaüstü/urban_total_delay_map.html\")"
      ],
      "metadata": {
        "id": "q-gmSrUNkBxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_pivot.drop(columns=['ATAŞEHİR', 'BELİRTİLMEMİŞ', 'BEYKOZ', 'KADIKÖY','KARTAL','TUZLA','ÇEKMEKÖY','ÜMRANİYE','ÜSKÜDAR','ŞİLE'], inplace=True)"
      ],
      "metadata": {
        "id": "bmf5RuFzkB5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Pivot the DataFrame to create a matrix where:\n",
        "#  - index is 'Saat Aralığı'\n",
        "#  - columns are 'İLÇE_ARGE'\n",
        "#  - values are 'Toplam Vaka Sayısı'\n",
        "data_pivot = hourly_counts.pivot(index='İLÇE_ARGE', columns='Saat Aralığı', values='Toplam Vaka Sayısı')\n",
        "data_pivot.drop(index=['ATAŞEHİR', 'BELİRTİLMEMİŞ', 'BEYKOZ', 'KADIKÖY','KARTAL','TUZLA','ÇEKMEKÖY','ÜMRANİYE','ÜSKÜDAR','ŞİLE'], inplace=True)\n",
        "\n",
        "fig = px.imshow(data_pivot,\n",
        "                labels=dict(x=\"Saat Aralığı\", y=\"İLÇE_ARGE\", color=\"Toplam Vaka Sayısı\"),\n",
        "                color_continuous_scale='hot'\n",
        "               )\n",
        "fig.update_xaxes(side=\"top\")\n",
        "fig.write_html(\"C:/Users/mkaya/Onedrive/Masaüstü/saatlik_vaka_sayisi.html\")"
      ],
      "metadata": {
        "id": "Z_Tcy_xRkB2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_counts = temp_df.groupby(['İLÇE_ARGE', 'MAHALLE_ARGE','Saat Aralığı']).agg({'Saat Aralığı':'count'})\n",
        "hourly_counts.rename(columns={'Saat Aralığı':'Toplam Vaka Sayısı'}, inplace=True)\n",
        "hourly_counts.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "Wwe-XRwxkB7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_counts"
      ],
      "metadata": {
        "id": "yYuvHL7HzJYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lat_lons= pd.read_excel('C:/Users/mkaya/Onedrive/Masaüstü/istanbul112_hidden/data/district locations/lat_lon.xlsx')"
      ],
      "metadata": {
        "id": "H4vpjOz8zKR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lat_lons.drop(columns=['Unnamed: 0'], inplace=True)"
      ],
      "metadata": {
        "id": "tKRLE-jwzkaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lat_lons"
      ],
      "metadata": {
        "id": "5xMcDvtYzr0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_counts.columns= ['İlçe Adı','Mahalle Adı', 'Saat Aralığı','Toplam Vaka Sayısı']"
      ],
      "metadata": {
        "id": "LYqkhE44z71u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_neighbourhoods= pd.merge(hourly_counts, lat_lons, on=['İlçe Adı','Mahalle Adı'], how='inner')"
      ],
      "metadata": {
        "id": "HaRaxJl7zw48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_neighbourhoods"
      ],
      "metadata": {
        "id": "42dPbFi1z4_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff = hourly_neighbourhoods\n",
        "fig = px.scatter_mapbox(dff, lat=\"Latitude\", lon=\"Longitude\", color=\"İlçe Adı\", size=\"Toplam Vaka Sayısı\",hover_data=['Toplam Vaka Sayısı'],hover_name='Mahalle Adı',size_max=15, zoom=10, animation_frame='Saat Aralığı',\n",
        "                  mapbox_style=\"carto-positron\")\n",
        "fig.write_html(\"C:/Users/mkaya/Onedrive/Masaüstü/saatlik_vaka3.html\")"
      ],
      "metadata": {
        "id": "kmx1ONX20RpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['VAKANIN ENLEMI']"
      ],
      "metadata": {
        "id": "AqGn1Xz0Nl9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['MONTH']"
      ],
      "metadata": {
        "id": "KRzdarmmPp_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dff = temp_df\n",
        "\n",
        "import plotly.express as px\n",
        "fig = px.density_mapbox(dff, lat='VAKANIN ENLEMI', lon='VAKANIN BOYLAMI', z='Value', radius=10,\n",
        "                        center=dict(lat=0, lon=180), zoom=0,animation_frame='MONTH',\n",
        "                        mapbox_style=\"open-street-map\")\n",
        "fig.write_html('vaka_sicaklik_haritasi.html')\n"
      ],
      "metadata": {
        "id": "pTklqTAp1E9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df[]"
      ],
      "metadata": {
        "id": "ahG9zu2I0I5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.rename(columns={'VAKANIN ENLEMI':'latitude', 'VAKANIN BOYLAMI':'longitude'}, inplace=True)"
      ],
      "metadata": {
        "id": "6I1xoJ3J0SMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(temp_df)"
      ],
      "metadata": {
        "id": "ZI40ftvh2-Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df= temp_df[temp_df['latitude']!='-']\n",
        "temp_df= temp_df[temp_df['longitude']!='-']"
      ],
      "metadata": {
        "id": "LMiXBCxN22Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fTVC99wf0t6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "7fGSJb3OV4RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall pillow"
      ],
      "metadata": {
        "id": "Nl0yrAwpV6g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yRsWm7DWZHAQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}